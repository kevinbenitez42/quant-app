{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notebook Description: This notebooks is used to Forecast individual assets based given a combination of features\n",
    "#I have found useful across my different studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "# 1.Implement feature selection by using models like Random Forest or XGBoost to filter out \n",
    "# features that are not important, but keep features that are highly interactive with each other\n",
    "# and have a non linear depenedence with the target variable\n",
    "\n",
    "# 2. Integrate Macroeconomic data into the model based on you domain knowledge of analyzing the markets\n",
    "\n",
    "# 3. Integrate Fundamental Company data into the model based on your domain knowledge of analyzing the markets\n",
    "\n",
    "# 4. Find interactive features acrooss fundamental,microeconomic and technical data that can be used to forecast the target variable    \n",
    "\n",
    "# 2. use a Shap value to understand the importance of each feature in the model as modeled by random forest or XGBoost\n",
    "\n",
    "# 2. Create non linear features such as differences, products, ratios, powers, polynomial features, etc\n",
    "\n",
    "# 3. Reduce the number of features by using PCA or other dimensionality reduction techniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all libaries and set parameters\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from darts.models import ExponentialSmoothing, AutoARIMA, BlockRNNModel, Prophet\n",
    "from darts.utils.utils import ModelMode, SeasonalityMode\n",
    "from darts.metrics import mape\n",
    "from darts.utils.timeseries_generation import datetime_attribute_timeseries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts import TimeSeries\n",
    "\n",
    "from statsmodels.tsa.stattools import acf, pacf, coint\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "from arch import arch_model\n",
    "\n",
    "# Quantapp imports\n",
    "from Quantapp.Model import Model\n",
    "from Quantapp.Computation import Computation, SequenceGenerator\n",
    "from Quantapp.Plotter import Plotter\n",
    "\n",
    "qm = Model()\n",
    "qc = Computation()\n",
    "qp = Plotter()\n",
    "sequence_generator = SequenceGenerator()\n",
    "\n",
    "\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define parameters for the notebook\n",
    "ticker = 'SPY'\n",
    "period = '10y'\n",
    "use_returns = False\n",
    "time_frame_returns = 1\n",
    "train_percentage = 0.85\n",
    "forecast_horizon = 21 # Number of days to forecast into the future\n",
    "input_length =200 # Number of days to use for training\n",
    "output_length = forecast_horizon # Number of days to forecast into the future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom Functions\n",
    "\n",
    "def plot_forecast(target, pred):\n",
    "    # Create traces\n",
    "    actual_trace = go.Scatter(\n",
    "        x=target.time_index,\n",
    "        y=target.values().flatten(),\n",
    "        mode='lines',\n",
    "        name='Actual'\n",
    "    )\n",
    "    \n",
    "    forecast_trace = go.Scatter(\n",
    "        x=pred.time_index,\n",
    "        y=pred.values().flatten(),\n",
    "        mode='lines',\n",
    "        name='Forecast'\n",
    "    )\n",
    "    \n",
    "    # Calculate mean and standard deviation of target\n",
    "    mean_value = target.values().flatten().mean()\n",
    "    std_value = target.values().flatten().std()\n",
    "    \n",
    "    mean_trace = go.Scatter(\n",
    "        x=target.time_index,\n",
    "        y=[mean_value] * len(target.time_index),\n",
    "        mode='lines',\n",
    "        name='Mean',\n",
    "        line=dict(dash='dash')\n",
    "    )\n",
    "    \n",
    "    # Create standard deviation traces\n",
    "    std_traces = []\n",
    "    for i in range(1, 4):\n",
    "        upper_trace = go.Scatter(\n",
    "            x=target.time_index,\n",
    "            y=[mean_value + i * std_value] * len(target.time_index),\n",
    "            mode='lines',\n",
    "            name=f'+{i} Std Dev',\n",
    "            line=dict(dash='dot')\n",
    "        )\n",
    "        lower_trace = go.Scatter(\n",
    "            x=target.time_index,\n",
    "            y=[mean_value - i * std_value] * len(target.time_index),\n",
    "            mode='lines',\n",
    "            name=f'-{i} Std Dev',\n",
    "            line=dict(dash='dot')\n",
    "        )\n",
    "        std_traces.extend([upper_trace, lower_trace])\n",
    "    \n",
    "    # Create the figure\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add traces to the figure\n",
    "    fig.add_trace(actual_trace)\n",
    "    fig.add_trace(forecast_trace)\n",
    "    fig.add_trace(mean_trace)\n",
    "    for trace in std_traces:\n",
    "        fig.add_trace(trace)\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title='Linear Regression Forecast',\n",
    "        xaxis_title='Time',\n",
    "        yaxis_title='Close',\n",
    "        legend=dict(x=0, y=1),\n",
    "        height=800,\n",
    "    )\n",
    "    \n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "    \n",
    "    #create a funciton the plots the backtest results against the actuals\n",
    "def plot_backtest_results_plotly(actual, predictions):\n",
    "    \"\"\"\n",
    "    Plots actual TimeSeries against predicted TimeSeries using Plotly with subplots,\n",
    "    including mean and ±1, ±2, ±3 standard deviation lines of the actuals,\n",
    "    and a residuals plot with mean and ±1, ±2, ±3 standard deviation lines in a separate subplot.\n",
    "    \n",
    "    Args:\n",
    "        actual (TimeSeries): The actual target TimeSeries from the test set.\n",
    "        predictions (TimeSeries): The predicted TimeSeries from the model.\n",
    "    \n",
    "    Returns:\n",
    "        None: Displays the interactive Plotly plot with subplots.\n",
    "    \"\"\"\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import numpy as np\n",
    "    \n",
    "    # Convert TimeSeries to DataFrame\n",
    "    actual_df = actual.pd_dataframe()\n",
    "    predictions_df = predictions.pd_dataframe()\n",
    "    \n",
    "    # Ensure both actual and predictions have the same columns\n",
    "    common_columns = actual_df.columns.intersection(predictions_df.columns)\n",
    "    if not common_columns.any():\n",
    "        raise ValueError(\"No common columns found between actual and predictions TimeSeries.\")\n",
    "    \n",
    "    # Initialize subplots: 2 rows, 1 column\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=(\"Backtest Predictions vs Actuals with Mean and Standard Deviations\",\n",
    "                        \"Residuals (Actual - Predicted) with Mean and Standard Deviations\"),\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    # Plot actual and predicted values with mean and std deviations in the first subplot\n",
    "    for column in common_columns:\n",
    "        # Plot actual values\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=actual_df.index,\n",
    "                y=actual_df[column],\n",
    "                mode='lines',\n",
    "                name=f'Actual {column}',\n",
    "                line=dict(color='blue')\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Plot predicted values\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=predictions_df.index,\n",
    "                y=predictions_df[column],\n",
    "                mode='lines',\n",
    "                name=f'Predicted {column}',\n",
    "                line=dict(color='red', dash='dash')\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Calculate mean and standard deviation\n",
    "        mean = actual_df[column].mean()\n",
    "        std = actual_df[column].std()\n",
    "        \n",
    "        # Plot mean line\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=actual_df.index,\n",
    "                y=[mean] * len(actual_df),\n",
    "                mode='lines',\n",
    "                name=f'{column} Mean',\n",
    "                line=dict(color='green', dash='dash')\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Plot ±1, ±2, ±3 standard deviation lines\n",
    "        for i in range(1, 4):\n",
    "            # Mean +i Std Dev\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=actual_df.index,\n",
    "                    y=[mean + i * std] * len(actual_df),\n",
    "                    mode='lines',\n",
    "                    name=f'{column} Mean +{i} Std Dev',\n",
    "                    line=dict(color='orange', dash='dot')\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            \n",
    "            # Mean -i Std Dev\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=actual_df.index,\n",
    "                    y=[mean - i * std] * len(actual_df),\n",
    "                    mode='lines',\n",
    "                    name=f'{column} Mean -{i} Std Dev',\n",
    "                    line=dict(color='orange', dash='dot')\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "    \n",
    "    # Calculate residuals\n",
    "    residuals_df = actual_df[common_columns] - predictions_df[common_columns]\n",
    "    \n",
    "    # Plot residuals with mean and std deviations in the second subplot\n",
    "    for column in common_columns:\n",
    "        # Calculate mean and standard deviation of residuals\n",
    "        residual_mean = residuals_df[column].mean()\n",
    "        residual_std = residuals_df[column].std()\n",
    "        \n",
    "        # Plot residuals\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=residuals_df.index,\n",
    "                y=residuals_df[column],\n",
    "                mode='lines',\n",
    "                name=f'Residuals {column}',\n",
    "                line=dict(color='purple')\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Plot mean residual line\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=residuals_df.index,\n",
    "                y=[residual_mean] * len(residuals_df),\n",
    "                mode='lines',\n",
    "                name=f'{column} Residual Mean',\n",
    "                line=dict(color='green', dash='dash')\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Plot ±1, ±2, ±3 standard deviation lines for residuals\n",
    "        for i in range(1, 4):\n",
    "            # Residual Mean +i Std Dev\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=residuals_df.index,\n",
    "                    y=[residual_mean + i * residual_std] * len(residuals_df),\n",
    "                    mode='lines',\n",
    "                    name=f'{column} Residual Mean +{i} Std Dev',\n",
    "                    line=dict(color='orange', dash='dot')\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "            \n",
    "            # Residual Mean -i Std Dev\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=residuals_df.index,\n",
    "                    y=[residual_mean - i * residual_std] * len(residuals_df),\n",
    "                    mode='lines',\n",
    "                    name=f'{column} Residual Mean -{i} Std Dev',\n",
    "                    line=dict(color='orange', dash='dot')\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "        \n",
    "        # Add a horizontal line at y=0 for reference\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=residuals_df.index,\n",
    "                y=[0] * len(residuals_df),\n",
    "                mode='lines',\n",
    "                name=f'Zero Line {column}',\n",
    "                line=dict(color='black', dash='dash')\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "    \n",
    "    # Update layout for better visualization\n",
    "    fig.update_layout(\n",
    "        title=\"Backtest Results with Residuals\",\n",
    "        template=\"plotly_dark\",\n",
    "        hovermode=\"x unified\",\n",
    "        legend=dict(x=0, y=1),\n",
    "        height=1400  # Increased height to accommodate additional lines\n",
    "    )\n",
    "    \n",
    "    # Update axes titles\n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Returns\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Residuals\", row=2, col=1)\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "#create a function that takes in stock prices, forecasted returns. and plots the future stock prices given the forecasted returns\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute Optimal Sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "sequences = [21,50,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Load raw data and engineer features\n",
    "\n",
    "ticker_list = [ticker]\n",
    "\n",
    "data = qc.load_and_prepare_data(\n",
    "    tickers=ticker_list,\n",
    "    period=period,\n",
    "    gen_returns=False,\n",
    "    gen_log_returns=False,\n",
    "    gen_cumulative_returns=False,\n",
    "    train_percentage=train_percentage\n",
    ")\n",
    "\n",
    "#reformat indexes to datetime without the minutes and seconds, just the month, day, year\n",
    "#make sure the index is a DateTimeIndex\n",
    "for ticker in data.keys():\n",
    "    data[ticker]['full'].index = pd.to_datetime(data[ticker]['full'].index.date)\n",
    "    data[ticker]['train'].index = pd.to_datetime(data[ticker]['train'].index.date)\n",
    "    data[ticker]['test'].index = pd.to_datetime(data[ticker]['test'].index.date)\n",
    "    \n",
    "def compute_feature_set(df, sequences, lags=range(1, 21)):\n",
    "    #df has columns 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close'\n",
    "    #drop columns 'Volume', 'Adj Close'\n",
    "    df_copy = df.copy().drop(columns=['Volume','Capital Gains','Stock Splits','Dividends'])\n",
    "    \n",
    "    features = {}\n",
    "    windows = sequences #use sequences as windows for computing moving averages\n",
    "    operations = ['differences', 'products', 'sums', 'ratios'] #operations to perform on pairwise features\n",
    "    transformations = ['polynomial','exponential','log','root']\n",
    "    #compute moving averages\n",
    "    # assign calculation to variable\n",
    "    \n",
    "    #standard caluclations\n",
    "    \n",
    "    moving_averages = qc.compute_moving_averages(df_copy['Close'], windows=windows, ma_type='simple')\n",
    "    standard_deviation = qc.compute_volatility(df_copy, windows=windows, method='close-to-close')\n",
    "    skewness = qc.compute_moments_ex_mean(df_copy['Close'], windows=sequences, moment='skew')\n",
    "    kurtosis = qc.compute_moments_ex_mean(df_copy['Close'], windows=sequences, moment='kurt')\n",
    "    sharpe = qc.calculate_risk_adjusted_returns(df_copy['Close'],windows=windows, ratio_type='sharpe')  \n",
    "    drawdown = qc.compute_drawdowns(df_copy['Close'], windows=windows)   \n",
    "\n",
    "\n",
    "    features['moving_averages'] = moving_averages\n",
    "    features['standard_deviation'] = standard_deviation\n",
    "    features['skewness'] = skewness\n",
    "    features['kurtosis'] = kurtosis\n",
    "    features['sharpe'] = sharpe\n",
    "    features['drawdown'] = drawdown\n",
    "    \n",
    "    #print the keys of the features dictionary sequentially\n",
    "\n",
    "    \n",
    "    features['lags'] = qc.compute_lags(df_copy, lags=lags)\n",
    "    \n",
    "    '''    \n",
    "    display(features['lags'])\n",
    "    #sort dictionary by keys\n",
    "    features = dict(sorted(features.items()))\n",
    "    for key in features.keys():\n",
    "        print(key)\n",
    "    '''\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def compute_features(dataframes, sequences, lags=None):\n",
    "    if lags is None:\n",
    "        lags = range(1, len(list(dataframes.values())[0]) + 1)\n",
    "    \n",
    "    all_features_dict = {}\n",
    "    \n",
    "    for name, df in dataframes.items():\n",
    "        features = compute_feature_set(df, sequences, lags)\n",
    "        # Prepend the name of the ticker to all columns in features\n",
    "        features = {f\"{name}_{key}\": value for key, value in features.items()}\n",
    "        #each feature holds a dataframe. prepend the name of the ticker to all columns in the dataframe\n",
    "        features = {key: value.add_prefix(f\"{name}_\") for key, value in features.items()}\n",
    "        all_features_dict.update(features)\n",
    "\n",
    "    reference_index = list(dataframes.values())[0].index\n",
    "    aligned_features = qc.align_features_to_index(all_features_dict, reference_index)\n",
    "\n",
    "    all_features = pd.concat(aligned_features.values(), axis=1)\n",
    "\n",
    "    return aligned_features, all_features\n",
    "\n",
    "dataframes = {}\n",
    "# Retrieve all tickers in data and append them to 'dataframes'\n",
    "for ticker in data.keys():\n",
    "    dataframes[ticker] = data[ticker]['full']\n",
    "\n",
    "tickers = list(data.keys())\n",
    "\n",
    "\n",
    "\n",
    "features_subsets, all_features = compute_features(\n",
    "    dataframes, \n",
    "    sequences,\n",
    "    lags=range(1, forecast_horizon+ 1)\n",
    ")\n",
    "\n",
    "features = all_features.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Feature Selection\n",
    "#to be implemented\n",
    "print('Feature Selection: To be implemented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3: Standardize the data and apply PCA\n",
    "#to be implemented\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Assuming 'all_features' is your DataFrame with the variables you want to analyze\n",
    "X = all_features.bfill() \n",
    "# Step 1: Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#display and plot scaled data\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "filtered_features = all_features\n",
    "\n",
    "X_scaled \n",
    "'''\n",
    "print('Standardize the data and apply PCA: To be implemented')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Data Preparation\n",
    "\n",
    "# Prepare the target variable\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "series_returns = pd.DataFrame(data[ticker]['full']['Close'].pct_change(forecast_horizon)).bfill()\n",
    "series_returns_ts = TimeSeries.from_dataframe(series_returns)\n",
    "\n",
    "split_point = int(len(series_returns_ts) * train_percentage)\n",
    "train_series_returns_ts = series_returns_ts[:split_point]\n",
    "test_series_returns_ts  = series_returns_ts[split_point:]\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Prepare the features\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "features = all_features.bfill()\n",
    "features_ts = TimeSeries.from_dataframe(features)\n",
    "\n",
    "scaler_features_ts = Scaler()\n",
    "features_ts_normalized = scaler_features_ts.fit_transform(features_ts)\n",
    "\n",
    "split_point = int(len(features_ts_normalized) * train_percentage)\n",
    "train_features_ts_normalized = features_ts_normalized[:split_point]\n",
    "test_features_ts_normalized  = features_ts_normalized[split_point:]\n",
    "#-------------------------------------------------------------\n",
    "\n",
    "# Debugging code\n",
    "print(\"Train series returns shape:\", train_series_returns_ts.pd_dataframe().shape)\n",
    "print(\"Test series returns shape:\", test_series_returns_ts.pd_dataframe().shape)\n",
    "print(\"Train features shape:\", train_features_ts_normalized.pd_dataframe().shape)\n",
    "print(\"Test features shape:\", test_features_ts_normalized.pd_dataframe().shape)\n",
    "print(' ')\n",
    "\n",
    "#check nan values\n",
    "print('Train series returns nan values:', train_series_returns_ts.pd_dataframe().isnull().sum().sum())\n",
    "print('Test series returns nan values:', test_series_returns_ts.pd_dataframe().isnull().sum().sum())\n",
    "print('Train features nan values:', train_features_ts_normalized.pd_dataframe().isnull().sum().sum())\n",
    "print('Test features nan values:', test_features_ts_normalized.pd_dataframe().isnull().sum().sum())\n",
    "\n",
    "# Ensure lengths match\n",
    "assert len(train_series_returns_ts) == len(train_features_ts_normalized), \"Train series and features length mismatch.\"\n",
    "assert len(test_series_returns_ts) == len(test_features_ts_normalized), \"Test series and features length mismatch.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model & Prediction: Linear Regression\n",
    "from darts.models import LinearRegressionModel\n",
    "from darts.models import LinearRegressionModel\n",
    "from darts.utils import statistics\n",
    "from darts.metrics import mape, mae\n",
    "from darts.utils.likelihood_models import GaussianLikelihood\n",
    "\n",
    "def train_fit_predict_linear_regression_model(target, past_cov, forecast_horizon):\n",
    "    model = LinearRegressionModel(\n",
    "        lags=12,\n",
    "        lags_past_covariates=12,\n",
    "        output_chunk_length=forecast_horizon,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        target,\n",
    "        past_covariates=past_cov,\n",
    "    )\n",
    "    \n",
    "    pred = model.predict(n=forecast_horizon)\n",
    "    return model, pred\n",
    "\n",
    "\n",
    "#prediction the full set\n",
    "model, pred_full = train_fit_predict_linear_regression_model(series_returns_ts, features_ts_normalized, forecast_horizon)\n",
    "\n",
    "#backtest the model (not retraining)\n",
    "backtest_predictions = model.historical_forecasts(\n",
    "    series_returns_ts,\n",
    "    past_covariates=features_ts_normalized,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    retrain=False,\n",
    "    enable_optimization=True\n",
    ")\n",
    "\n",
    "\n",
    "#plot the backtest results\n",
    "plot_backtest_results_plotly(series_returns_ts, backtest_predictions)\n",
    "\n",
    "#plot the forecast for the full set\n",
    "plot_forecast(series_returns_ts, pred_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model & Prediction:: NBeats or Nhits (with probabilistic forecasts)\n",
    "from darts.models import NHiTSModel\n",
    "\n",
    "def train_fit_predict_nhits_model(target, past_cov, forecast_horizon):\n",
    "    \"\"\"\n",
    "    Train, fit, and predict using the NHiTS model.\n",
    "    \n",
    "    Args:\n",
    "        target (TimeSeries): The target TimeSeries.\n",
    "        past_cov (TimeSeries): The past covariates TimeSeries.\n",
    "        forecast_horizon (int): The number of steps to forecast.\n",
    "    \n",
    "    Returns:\n",
    "        model (NHiTSModel): The trained NHiTS model.\n",
    "        pred (TimeSeries): The forecasted TimeSeries.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    model = NHiTSModel(\n",
    "        input_chunk_length=12,\n",
    "        output_chunk_length=forecast_horizon,\n",
    "        num_blocks=4,\n",
    "        num_layers=4,\n",
    "        n_epochs=100,\n",
    "        nr_epochs_val_period=10,\n",
    "        batch_size=32,\n",
    "        model_name=\"NHiTS_Model\",\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        series=target,\n",
    "        past_covariates=past_cov,\n",
    "    )\n",
    "    \n",
    "    pred = model.predict(n=forecast_horizon)\n",
    "    return model, pred\n",
    "\n",
    "\n",
    "\n",
    "#prediction the full set\n",
    "model, pred_full = train_fit_predict_nhits_model(series_returns_ts, features_ts_normalized, forecast_horizon)\n",
    "\n",
    "#backtest the model (not retraining)\n",
    "backtest_predictions = model.historical_forecasts(\n",
    "    series_returns_ts,\n",
    "    past_covariates=features_ts_normalized,\n",
    "    forecast_horizon=forecast_horizon,\n",
    "    retrain=False,\n",
    "    enable_optimization=True\n",
    ")\n",
    "\n",
    "\n",
    "#plot the backtest results\n",
    "plot_backtest_results_plotly(series_returns_ts, backtest_predictions)\n",
    "\n",
    "#plot the forecast for the full set\n",
    "plot_forecast(series_returns_ts, pred_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model: Torch Model (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model: Transformer Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
