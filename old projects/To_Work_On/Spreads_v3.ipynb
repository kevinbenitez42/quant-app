{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "#Retrieve Asset Information\n",
    "sp500_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "dow_url = 'https://en.wikipedia.org/wiki/Dow_Jones_Industrial_Average'\n",
    "nasdaq_url = 'https://en.wikipedia.org/wiki/NASDAQ-100'\n",
    "\n",
    "\n",
    "time_frame_week = 7\n",
    "time_frame_short = 21\n",
    "time_frame_mid   = 50\n",
    "time_frame_long = 200\n",
    "period     = '10y'\n",
    "\n",
    "risk_free_rate = 0.02 / 252  # Annualized risk-free rate divided by trading days\n",
    "benchmark = 'SPY'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1319bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Methods & Classes\n",
    "#Define Parameters\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import yfinance as yf\n",
    "'''from Quantapp.Computation import Computation\n",
    "from Quantapp.Algorithm   import Algorithm\n",
    "comp = Computation()\n",
    "algorithm = Algorithm()'''\n",
    "#plt.rcParams[\"figure.figsize\"] = (20, 7)\n",
    "\n",
    "\n",
    "def calculate_sortino_ratio(returns):\n",
    "    excess_returns = returns - risk_free_rate\n",
    "    downside_deviation = excess_returns[excess_returns < 0].std()\n",
    "    sortino_ratio = excess_returns.mean() / downside_deviation if downside_deviation != 0 else np.nan\n",
    "    return sortino_ratio\n",
    "\n",
    "def calculate_risk_adjusted_returns(df, time_frame):\n",
    "    daily_returns = df.pct_change()\n",
    "    rolling_sortino_ratio = daily_returns.rolling(window=time_frame).apply(calculate_sortino_ratio)\n",
    "    return rolling_sortino_ratio\n",
    "\n",
    "def generate_series(tickers):\n",
    "    tickers = [ticker.replace('.', '-') for ticker in tickers]\n",
    "    try:\n",
    "        df = yf.download(tickers, period=period)['Close']\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching data: {e}\")\n",
    "        return pd.DataFrame()  \n",
    "    df.columns = [col.replace('-', '.') for col in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_returns(returns, time_frame):\n",
    "    threshold = 0\n",
    "    fig = px.line(returns , x=returns.index, y=returns.columns)\n",
    "    fig.add_hline(y=threshold, line_dash=\"dash\", line_color=\"red\", annotation_text=f\"y={threshold}\")\n",
    "    fig.add_hline(y=threshold, line_dash=\"dash\", line_color=\"red\", annotation_text=f\"y={threshold}\")\n",
    "    fig.show()\n",
    "\n",
    "def create_spreads(asset_series, benchmark_series, time_frame, mode='standard'):\n",
    "    \n",
    "    if mode == 'standard':\n",
    "        asset_returns = asset_series.pct_change(time_frame)\n",
    "        benchmark_returns= benchmark_series.pct_change(time_frame)\n",
    "    elif mode == 'sortino':\n",
    "        asset_returns = calculate_risk_adjusted_returns(asset_series, time_frame)\n",
    "        benchmark_returns= calculate_risk_adjusted_returns(benchmark_series, time_frame)\n",
    "\n",
    "    benchmark_minus_asset = asset_returns.apply(lambda x: benchmark_returns - x)\n",
    "    benchmark_minus_asset.columns = [\"Benchmark\" + \"_minus_\" + col for col in benchmark_minus_asset.columns]\n",
    "    return benchmark_minus_asset    \n",
    "'''\n",
    "def create_spreads(asset_series, benchmark_series, time_frame, mode='standard'):\n",
    "    asset_series = asset_series.ffill().dropna()\n",
    "    benchmark_series = benchmark_series.ffill().dropna()\n",
    "    if mode == 'standard':\n",
    "        asset_returns = asset_series.pct_change(time_frame)\n",
    "        benchmark_returns= benchmark_series.pct_change(time_frame)\n",
    "    elif mode == 'sortino':\n",
    "        asset_returns = calculate_risk_adjusted_returns(asset_series, time_frame)\n",
    "        benchmark_returns= calculate_risk_adjusted_returns(benchmark_series, time_frame) \n",
    "\n",
    "    benchmark_returnsn\n",
    "\n",
    "    print(benchmark_minus_asset)\n",
    "    benchmark_minus_asset.columns = [\"Benchmark\" + \"_minus_\" + col for col in benchmark_minus_asset.columns]\n",
    "    return benchmark_minus_asset\n",
    "'''\n",
    "def create_spread_plot(asset_spreads):\n",
    "    spread_threshold = 0\n",
    "    spread           = asset_spreads\n",
    "    mean             = spread[spread>=0].mean()\n",
    "    std_dev = spread[spread >= 0].std()\n",
    "    #spread = asset_spreads[:200]\n",
    "\n",
    "\n",
    "    fig = px.line(spread)\n",
    "    fig.update_layout(title=asset_spreads.name)\n",
    "    fig.add_hline(y=spread_threshold, line_dash=\"dash\", line_color=\"red\", annotation_text=f\"y={spread_threshold}\")\n",
    "    fig.add_hline(y=mean , line_color=\"red\", annotation_text=\"mean\")\n",
    "    fig.add_hline(y=mean + std_dev, line_dash=\"dash\", line_color=\"blue\", \n",
    "                  annotation_text=\"mean + 1 std dev\", annotation_position=\"bottom right\")\n",
    "    fig.add_hline(y=mean - std_dev, line_dash=\"dash\", line_color=\"blue\", \n",
    "                  annotation_text=\"mean - 1 std dev\", annotation_position=\"bottom right\")\n",
    "    fig.add_hline(y=mean + 2*std_dev, line_dash=\"dot\", line_color=\"green\", \n",
    "                  annotation_text=\"mean + 2 std dev\", annotation_position=\"bottom right\")\n",
    "    fig.add_hline(y=mean - 2*std_dev, line_dash=\"dot\", line_color=\"green\", \n",
    "                  annotation_text=\"mean - 2 std dev\", annotation_position=\"bottom right\")\n",
    "    fig.add_shape(type=\"rect\",\n",
    "                  xref=\"paper\", yref=\"y\",\n",
    "                  x0=0, y0=mean, x1=1, y1=spread.max(),\n",
    "                  fillcolor=\"green\", opacity=0.2, line_width=0)\n",
    "    #fig.update_layout(height=800)\n",
    "    return fig\n",
    "\n",
    "def create_side_by_side_subplots(fig1, fig2):\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=(fig1.layout.title.text, fig2.layout.title.text))\n",
    "    \n",
    "    for trace in fig1.data:\n",
    "        fig.add_trace(trace,row=1,col=1)\n",
    "\n",
    "    for trace in fig2.data:\n",
    "        fig.add_trace(trace,row=1,col=2)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_multiple_spreads(assets):\n",
    "    for column in assets:\n",
    "       asset_spreads = assets[column]\n",
    "       create_spread_plot(asset_spreads).show()\n",
    "\n",
    "def plot_risk_adjusted_returns(series,time_frame):\n",
    "    series_adjusted_returns = calculate_risk_adjusted_returns(series,time_frame)\n",
    "    negative_returns = series_adjusted_returns[series_adjusted_returns<0]\n",
    "    mean = negative_returns.mean()\n",
    "    standard_deviation = negative_returns.std()\n",
    "    standard_deviation_level_three_fourths = mean - .5 * standard_deviation\n",
    "    standard_deviation_level_single        = mean - standard_deviation\n",
    "\n",
    "    fig = px.line(series_adjusted_returns)\n",
    "\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"black\", \n",
    "                annotation_text=\"Zero Line\", annotation_position=\"bottom right\")\n",
    "    fig.add_hline(y=mean, line_dash=\"dot\", line_color=\"blue\", \n",
    "                annotation_text=f\"Mean of negative returns: {mean:.2f}\", annotation_position=\"top right\")\n",
    "    fig.add_hline(y=standard_deviation_level_three_fourths , line_dash=\"dashdot\", line_color=\"red\", \n",
    "                annotation_text=f\".75 Std Dev: {standard_deviation_level_three_fourths :.2f}\", annotation_position=\"top right\")\n",
    "    fig.add_hline(y=standard_deviation_level_single, line_dash=\"dashdot\", line_color=\"red\", \n",
    "                annotation_text=f\"1 Std Dev: {standard_deviation_level_single:.2f}\", annotation_position=\"top right\")\n",
    "\n",
    "    fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        x0=series_adjusted_returns.index.min(),\n",
    "        x1=series_adjusted_returns.index.max(),\n",
    "        y0=standard_deviation_level_three_fourths,\n",
    "        y1=standard_deviation_level_single,\n",
    "        fillcolor=\"green\",\n",
    "        opacity=0.2,\n",
    "        line_width=0,\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "def filter_assets_by_positive_spread_std(asset_spreads):\n",
    "    spreads = asset_spreads\n",
    "    positive_spreads = spreads[spreads >= 0] \n",
    "    \n",
    "    mean = positive_spreads.mean()\n",
    "    std_dev = positive_spreads.std()\n",
    "\n",
    "    latest_spread = spreads.iloc[-1]\n",
    "    threshold = mean + std_dev\n",
    "\n",
    "    return latest_spread>=threshold\n",
    "\n",
    "\n",
    "def filter_assets_below_negative_std(asset_spreads):\n",
    "    if not isinstance(asset_spreads, pd.Series):\n",
    "        raise TypeError(\"asset_spreads must be a pandas Series\")\n",
    "\n",
    "    negative_spreads = asset_spreads[asset_spreads < 0]\n",
    "    if negative_spreads.empty:\n",
    "        return pd.Series(dtype=bool)  \n",
    "    \n",
    "    mean_negative = negative_spreads.mean()\n",
    "    std_dev_negative = negative_spreads.std()\n",
    "\n",
    "    threshold_negative = mean_negative - 0.75 * std_dev_negative\n",
    "    return asset_spreads < threshold_negative\n",
    "\n",
    "def get_sector_info(ticker):\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        sector = stock.info.get('sector', 'N/A')\n",
    "        sub_industry = stock.info.get('industry', 'N/A')\n",
    "        return {'Ticker': ticker, 'Sector': sector, 'Sub-Industry': sub_industry}\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return {'Ticker': ticker, 'Sector': 'N/A', 'Sub-Industry': 'N/A'}\n",
    "    \n",
    "\n",
    "'''\n",
    "def get_market_caps(table):\n",
    "    tickers = table['Symbol'].tolist()\n",
    "    tickers = ['BRK-B'if symbol == 'BRK.B' else symbol for symbol in tickers]\n",
    "    tickers = ['BF-B'if symbol == 'BF.B' else symbol for symbol in tickers]\n",
    "\n",
    "    sectors = []\n",
    "    sub_industry = []\n",
    "    market_cap = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "\n",
    "        info = get_sector_info(ticker)\n",
    "        sectors.append(info['Sector'])\n",
    "        sub_industry.append(info['Sub-Industry'])\n",
    "        market_cap.append(yf.Ticker(ticker).info.get('marketCap'))\n",
    "    \n",
    "    table['Sector'] = sectors\n",
    "    table['Sub-Industry'] = sub_industry\n",
    "    table['Market Cap'] = market_cap\n",
    "\n",
    "    return table\n",
    "'''\n",
    "\n",
    "def get_market_caps(table):\n",
    "    print(\"Starting market cap retrieval process...\")\n",
    "    \n",
    "    tickers = table['Symbol'].tolist()\n",
    "    print(f\"Original tickers: {tickers[:10]}...\")  # Print first 10 for brevity\n",
    "\n",
    "    tickers = ['BRK-B' if symbol == 'BRK.B' else symbol for symbol in tickers]\n",
    "    tickers = ['BF-B' if symbol == 'BF.B' else symbol for symbol in tickers]\n",
    "    print(f\"Adjusted tickers: {tickers[:10]}...\")  # Print first 10 for brevity\n",
    "\n",
    "    sectors = []\n",
    "    sub_industry = []\n",
    "    market_cap = []\n",
    "\n",
    "    for ticker in tickers:\n",
    "        print(f\"Processing ticker: {ticker}\")\n",
    "        \n",
    "        info = get_sector_info(ticker)\n",
    "        sectors.append(info['Sector'])\n",
    "        sub_industry.append(info['Sub-Industry'])\n",
    "        market_cap.append(yf.Ticker(ticker).info.get('marketCap'))\n",
    "\n",
    "        print(f\"Retrieved info for {ticker}: Sector - {info['Sector']}, Sub-Industry - {info['Sub-Industry']}, Market Cap - {market_cap[-1]}\")\n",
    "\n",
    "    table['Sector'] = sectors\n",
    "    table['Sub-Industry'] = sub_industry\n",
    "    table['Market Cap'] = market_cap\n",
    "    \n",
    "    print(\"Market cap retrieval process completed.\")\n",
    "    return table\n",
    "def plot_market_caps(info):\n",
    "    market_caps = pd.DataFrame(info[['Symbol','Market Cap']])\n",
    "    #market_caps = market_caps.sort_values(by='Market Cap',ascending=False)\n",
    "    market_caps = market_caps.sort_values(by='Market Cap')\n",
    "    market_caps['Log Market Cap'] = np.log(market_caps['Market Cap'])\n",
    "    percentiles = np.percentile(market_caps['Log Market Cap'], [60, 90])\n",
    "\n",
    "    def categorize(market_cap):\n",
    "        if market_cap <= percentiles[0]:\n",
    "            return 'Small-Cap'\n",
    "        elif market_cap <= percentiles[1]:\n",
    "            return 'Mid-Cap'\n",
    "        else:\n",
    "            return 'Large-Cap'\n",
    "\n",
    "    market_caps['category'] = market_caps['Log Market Cap'].apply(categorize)\n",
    "    value_counts = market_caps['category'].value_counts()\n",
    "    fig = px.bar(market_caps, x='Symbol', y='Market Cap', \n",
    "                labels={'Ticker': 'Symbol', 'Market Cap': 'Market Cap (Billions USD)'},\n",
    "                title='Market Capitalizations Companies')\n",
    "\n",
    "    # Customize layout if needed\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Ticker\",\n",
    "        yaxis_title=\"Market Cap (Billions USD)\"\n",
    "    )\n",
    "    mid_to_large= len(market_caps) - market_caps.tail(value_counts['Large-Cap']).count()['Symbol']+ 2.5\n",
    "    small_to_mid= market_caps.tail(value_counts['Small-Cap']).count()['Symbol'] - .5\n",
    "    market_caps[market_caps['category'] == 'Mid-Cap']\n",
    "\n",
    "    # Add vertical lines to separate the caps\n",
    "    fig.add_vline(x=small_to_mid, line=dict(color=\"Red\", width=2, dash=\"dashdot\"), annotation_text=\"Small to Mid\", annotation_position=\"top left\")\n",
    "    fig.add_vline(x=mid_to_large, line=dict(color=\"Blue\", width=2, dash=\"dashdot\"), annotation_text=\"Mid to Large\", annotation_position=\"top left\")\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b9d2a9-7952-46e4-be29-1d6dc9cf9dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load: retrieve all tickers\n",
    "\n",
    "\n",
    "sp500_table = pd.read_html(sp500_url)[0]\n",
    "qqq_table = pd.read_html(nasdaq_url)[4]\n",
    "dia_table = pd.read_html(dow_url)[1]\n",
    "\n",
    "sp500_table = sp500_table[['Symbol', 'GICS Sector', 'GICS Sub-Industry']]\n",
    "sp500_table = sp500_table.rename(columns={'GICS Sector' : 'Sector', \"GICS Sub-Industry\": 'Sub-Industry'})\n",
    "\n",
    "qqq_table = qqq_table[['Ticker', 'GICS Sector', 'GICS Sub-Industry']]\n",
    "qqq_table = qqq_table.rename(columns={'Ticker' : 'Symbol','GICS Sector' : 'Sector', \"GICS Sub-Industry\": 'Sub-Industry'})\n",
    "qqq_table = pd.merge(qqq_table, sp500_table[['Symbol', 'Sub-Industry']], on='Symbol', how='left')\n",
    "qqq_table['Sub-Industry'] = qqq_table['Sub-Industry_x'].combine_first(qqq_table['Sub-Industry_y'])\n",
    "qqq_table = qqq_table.drop(columns=['Sub-Industry_x', 'Sub-Industry_y'])\n",
    "\n",
    "tables = pd.read_html(dow_url)\n",
    "dia_table = tables[1]\n",
    "dia_table = dia_table[['Symbol', 'Industry']]\n",
    "dia_table = pd.merge(dia_table, sp500_table[['Symbol', 'Sector']], on='Symbol', how='left')\n",
    "dia_table = pd.merge(dia_table, sp500_table[['Symbol', 'Sub-Industry']], on='Symbol', how='left')\n",
    "dia_table = dia_table.drop(columns=['Industry'])\n",
    "\n",
    "xlk_table = sp500_table[sp500_table['Sector'] == 'Information Technology']\n",
    "xlf_table = sp500_table[sp500_table['Sector'] == 'Financials']\n",
    "xlv_table = sp500_table[sp500_table['Sector'] == 'Health Care']\n",
    "xli_table = sp500_table[sp500_table['Sector'] == 'Industrials']\n",
    "xly_table = sp500_table[sp500_table['Sector'] == 'Consumer Discretionary']\n",
    "xle_table = sp500_table[sp500_table['Sector'] == 'Energy']\n",
    "xlb_table = sp500_table[sp500_table['Sector'] == 'Materials']\n",
    "xlc_table = sp500_table[sp500_table['Sector'] == 'Communication Services']\n",
    "xlre_table = sp500_table[sp500_table['Sector'] == 'Real Estate']\n",
    "xlc_table = sp500_table[sp500_table['Sector'] == 'Communication Services']\n",
    "xlp_table = sp500_table[sp500_table['Sector'] == 'Consumer Staples']\n",
    "xlu_table = sp500_table[sp500_table['Sector'] == 'Utilities']\n",
    "\n",
    "INDICES          = ['SPY','QQQ','DIA','IWM']\n",
    "SECTORS          = ['SPY','XLF','XLK','XLV','XLC','XLI','XLU','XLB','VNQ','XLP','XLY','XBI','XLE']\n",
    "INDUSTRIES       = ['SPY', 'SMH', 'KRE','KIE', 'KBE']\n",
    "SPY_HOLDINGS     = sp500_table['Symbol'].tolist()\n",
    "QQQ_HOLDINGS     = qqq_table['Symbol'].tolist()\n",
    "DIA_HOLDINGS     = dia_table['Symbol'].tolist()\n",
    "XLK_HOLDINGS     = xlk_table['Symbol'].tolist()\n",
    "XLF_HOLDINGS     = xlf_table['Symbol'].tolist()\n",
    "XLI_HOLDINGS     = xli_table['Symbol'].tolist()\n",
    "XLV_HOLDINGS     = xlv_table['Symbol'].tolist()\n",
    "XLU_HOLDINGS     = xlu_table['Symbol'].tolist()\n",
    "XLF_HOLDINGS     = xlf_table['Symbol'].tolist()\n",
    "XLB_HOLDINGS     = xlb_table['Symbol'].tolist()\n",
    "XLY_HOLDINGS     = xly_table['Symbol'].tolist()\n",
    "XLRE_HOLDINGS    = xlre_table['Symbol'].tolist()\n",
    "XLC_HOLDINGS     = xlc_table['Symbol'].tolist()\n",
    "XLE_HOLDINGS     = xle_table['Symbol'].tolist()\n",
    "XLP_HOLDINGS     = xlp_table['Symbol'].tolist()\n",
    "BONDS            = ['AGG','IEF','TLT', 'HYG','LQD','TIPS', 'BKLN']\n",
    "PRECIOUS_METALS  = ['GLD','SLV','GDX','XME']\n",
    "CRYPTO           = ['GBTC','BLOK']\n",
    "ENERGY           = ['USO','UNG','OIH','XOP','TAN','ICLN','URA','URNM','GUSH','KOLD']\n",
    "CAPITALIZATIONS  = ['SPY', 'IJH' , 'IJR']\n",
    "INNOVATION       = ['ARKG','ARKF','ARKK']\n",
    "LONG_LEVERAGE    = ['TQQQ','SOXL','SPXL','TNA','BOIL','NUGT','ERX','DPST']\n",
    "SHORT_LEVERAGE   = ['SQQQ','SPXS','UDOW','SSO','TECL','FAS','NVDA','TQQQ', 'VXX','UVXY','VIXY','UVIX','SVXY','SOXS','TZA','USD','TSLL','LABU','DPST','NUGT','CONL']\n",
    "FOREIGN_MARKETS  = ['EWZ','EWJ','EWA','EWG','EWW','EEM','EFA','FEZ','INDA','EWU','EWG']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load: retrieve market caps\n",
    "\n",
    "\n",
    "\n",
    "dow_info    = get_market_caps(qqq_table)\n",
    "nasdaq_info = get_market_caps(qqq_table)\n",
    "sp500_info  = get_market_caps(sp500_table)\n",
    "\n",
    "xlk_info    = sp500_info[ sp500_info['Sector'] == 'Technology']\n",
    "xlf_info    = sp500_info[sp500_info['Sector'] == 'Financial Services']\n",
    "xli_info    = sp500_info[ sp500_info['Sector'] == 'Industrials']\n",
    "xlv_info    = sp500_info[sp500_info['Sector'] == 'Healthcare']\n",
    "xlu_info    = sp500_info[ sp500_info['Sector'] == 'Utilities']\n",
    "xlb_info    = sp500_info[sp500_info['Sector'] == 'Basic Materials']\n",
    "xly_info    = sp500_info[ sp500_info['Sector'] == 'Consumer Cyclical']\n",
    "xlc_info    = sp500_info[sp500_info['Sector'] == 'Communication Services']\n",
    "xle_info    = sp500_info[ sp500_info['Sector'] == 'Energy']\n",
    "xlre_info    = sp500_info[ sp500_info['Sector'] == 'Real Estate']\n",
    "xlp_info    = sp500_info[ sp500_info['Sector'] == 'Consumer Defensive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8e3344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load: retrieve prices\n",
    "'''\n",
    "indices_df             = generate_series(INDICES)\n",
    "sectors_df            = generate_series(SECTORS)\n",
    "industries_df         = generate_series(INDUSTRIES)\n",
    "qqq_holdings_df        = generate_series(QQQ_HOLDINGS)\n",
    "dia_holdings_df        = generate_series(DIA_HOLDINGS)\n",
    "xlk_holdings_df       = generate_series(XLK_HOLDINGS)\n",
    "xlf_holdings_df      = generate_series(XLF_HOLDINGS)\n",
    "xli_holdings_df        = generate_series(XLI_HOLDINGS)\n",
    "xlv_holdings_df       = generate_series(XLV_HOLDINGS)\n",
    "xlu_holdings_df        = generate_series(XLU_HOLDINGS)\n",
    "xlb_holdings_df        = generate_series(XLB_HOLDINGS)\n",
    "xly_holdings_df        = generate_series(XLY_HOLDINGS)\n",
    "xlc_holdings_df       = generate_series(XLC_HOLDINGS)\n",
    "xle_holdings_df        = generate_series(XLE_HOLDINGS)\n",
    "xlre_holdings_df       = generate_series(XLRE_HOLDINGS)\n",
    "xlp_holdings_df        = generate_series(XLP_HOLDINGS)\n",
    "\n",
    "\n",
    "all_series = pd.concat([\n",
    "    indices_df,\n",
    "    sectors_df,\n",
    "    industries_df,\n",
    "    qqq_holdings_df,\n",
    "    dia_holdings_df,\n",
    "    xlk_holdings_df,\n",
    "    xlf_holdings_df,\n",
    "    xli_holdings_df,\n",
    "    xlv_holdings_df,\n",
    "    xlu_holdings_df,\n",
    "    xlb_holdings_df,\n",
    "    xly_holdings_df,\n",
    "    xlc_holdings_df,\n",
    "    xle_holdings_df,\n",
    "    xlre_holdings_df,\n",
    "    xlp_holdings_df,\n",
    "], axis=1)\n",
    "\n",
    "benchmark_series           = all_series[benchmark]\n",
    "benchmark_series=benchmark_series.loc[:, ~benchmark_series.columns.duplicated()]\n",
    "\n",
    "all_series = pd.concat([\n",
    "    all_series,\n",
    "    benchmark_series,\n",
    "], axis=1)\n",
    "\n",
    "all_series=all_series.loc[:, ~all_series.columns.duplicated()]\n",
    "all_series\n",
    "\n",
    "'''\n",
    "\n",
    "indices_df             = generate_series(INDICES)\n",
    "sectors_df            = generate_series(SECTORS)\n",
    "industries_df         = generate_series(INDUSTRIES)\n",
    "qqq_holdings_df        = generate_series(QQQ_HOLDINGS)\n",
    "dia_holdings_df        = generate_series(DIA_HOLDINGS)\n",
    "xlk_holdings_df       = generate_series(XLK_HOLDINGS)\n",
    "xlf_holdings_df      = generate_series(XLF_HOLDINGS)\n",
    "xli_holdings_df        = generate_series(XLI_HOLDINGS)\n",
    "xlv_holdings_df       = generate_series(XLV_HOLDINGS)\n",
    "xlu_holdings_df        = generate_series(XLU_HOLDINGS)\n",
    "xlb_holdings_df        = generate_series(XLB_HOLDINGS)\n",
    "xly_holdings_df        = generate_series(XLY_HOLDINGS)\n",
    "xlc_holdings_df       = generate_series(XLC_HOLDINGS)\n",
    "xle_holdings_df        = generate_series(XLE_HOLDINGS)\n",
    "xlre_holdings_df       = generate_series(XLRE_HOLDINGS)\n",
    "xlp_holdings_df        = generate_series(XLP_HOLDINGS)\n",
    "\n",
    "\n",
    "all_series = pd.concat([\n",
    "    indices_df,\n",
    "    sectors_df,\n",
    "    industries_df,\n",
    "    qqq_holdings_df,\n",
    "    dia_holdings_df,\n",
    "    xlk_holdings_df,\n",
    "    xlf_holdings_df,\n",
    "    xli_holdings_df,\n",
    "    xlv_holdings_df,\n",
    "    xlu_holdings_df,\n",
    "    xlb_holdings_df,\n",
    "    xly_holdings_df,\n",
    "    xlc_holdings_df,\n",
    "    xle_holdings_df,\n",
    "    xlre_holdings_df,\n",
    "    xlp_holdings_df,\n",
    "], axis=1)\n",
    "\n",
    "benchmark_series           = all_series[benchmark]\n",
    "benchmark_series=benchmark_series.loc[:, ~benchmark_series.columns.duplicated()]\n",
    "\n",
    "all_series = pd.concat([\n",
    "    all_series,\n",
    "    benchmark_series\n",
    "], axis=1)\n",
    "\n",
    "benchmark_series = pd.Series(benchmark_series['SPY'])\n",
    "all_series=all_series.loc[:, ~all_series.columns.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc3f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate: spreads\n",
    "mode='standard'\n",
    "\n",
    "benchmark_minus_indices_week          = create_spreads(indices_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_sectors_week          = create_spreads(sectors_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_industries_week       = create_spreads(industries_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_dia_holdings_week       = create_spreads(dia_holdings_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_qqq_holdings_week       = create_spreads(qqq_holdings_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_xlk_holdings_week       = create_spreads(xlk_holdings_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_xlf_holdings_week       = create_spreads(xlf_holdings_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_xli_holdings_week       = create_spreads(xli_holdings_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_xlv_holdings_week       = create_spreads(xlv_holdings_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_xlu_holdings_week       = create_spreads(xlu_holdings_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_xlb_holdings_week       = create_spreads(xlb_holdings_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_xly_holdings_week       = create_spreads(xly_holdings_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_xlc_holdings_week       = create_spreads(xlc_holdings_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_xle_holdings_week       = create_spreads(xle_holdings_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_xlre_holdings_week       = create_spreads(xlre_holdings_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "benchmark_minus_xlp_holdings_week       = create_spreads(xlp_holdings_df, benchmark_series, time_frame=time_frame_week,mode=mode)\n",
    "\n",
    "\n",
    "benchmark_minus_all_series_week= pd.concat([\n",
    "    benchmark_minus_indices_week,\n",
    "    benchmark_minus_sectors_week,\n",
    "    benchmark_minus_industries_week,\n",
    "    benchmark_minus_dia_holdings_week,\n",
    "    benchmark_minus_xlk_holdings_week,\n",
    "    benchmark_minus_xlf_holdings_week,\n",
    "    benchmark_minus_xli_holdings_week,\n",
    "    benchmark_minus_xlv_holdings_week,\n",
    "    benchmark_minus_xlu_holdings_week,\n",
    "    benchmark_minus_xlb_holdings_week,\n",
    "    benchmark_minus_xly_holdings_week,\n",
    "    benchmark_minus_xlc_holdings_week,\n",
    "    benchmark_minus_xle_holdings_week,\n",
    "    benchmark_minus_xlre_holdings_week,\n",
    "    benchmark_minus_xlp_holdings_week\n",
    "], axis=1)\n",
    "\n",
    "benchmark_minus_all_series_week=benchmark_minus_all_series_week.loc[:, ~benchmark_minus_all_series_week.columns.duplicated()]\n",
    "\n",
    "\n",
    "benchmark_minus_indices_short          = create_spreads(indices_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_sectors_short          = create_spreads(sectors_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_industries_short       = create_spreads(industries_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_dia_holdings_short       = create_spreads(dia_holdings_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_qqq_holdings_short       = create_spreads(qqq_holdings_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_xlk_holdings_short       = create_spreads(xlk_holdings_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_xlf_holdings_short       = create_spreads(xlf_holdings_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_xli_holdings_short       = create_spreads(xli_holdings_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_xlv_holdings_short       = create_spreads(xlv_holdings_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_xlu_holdings_short       = create_spreads(xlu_holdings_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_xlb_holdings_short       = create_spreads(xlb_holdings_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_xly_holdings_short       = create_spreads(xly_holdings_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_xlc_holdings_short       = create_spreads(xlc_holdings_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_xle_holdings_short       = create_spreads(xle_holdings_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_xlre_holdings_short       = create_spreads(xlre_holdings_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "benchmark_minus_xlp_holdings_short       = create_spreads(xlp_holdings_df, benchmark_series, time_frame=time_frame_short,mode=mode)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "benchmark_minus_all_series_short= pd.concat([\n",
    "    benchmark_minus_indices_short,\n",
    "    benchmark_minus_sectors_short,\n",
    "    benchmark_minus_industries_short,\n",
    "    benchmark_minus_dia_holdings_short,\n",
    "    benchmark_minus_xlk_holdings_short,\n",
    "    benchmark_minus_xlf_holdings_short,\n",
    "    benchmark_minus_xli_holdings_short,\n",
    "    benchmark_minus_xlv_holdings_short,\n",
    "    benchmark_minus_xlu_holdings_short,\n",
    "    benchmark_minus_xlb_holdings_short,\n",
    "    benchmark_minus_xly_holdings_short,\n",
    "    benchmark_minus_xlc_holdings_short,\n",
    "    benchmark_minus_xle_holdings_short,\n",
    "    benchmark_minus_xlre_holdings_short,\n",
    "    benchmark_minus_xlp_holdings_short\n",
    "], axis=1)\n",
    "\n",
    "benchmark_minus_all_series_short=benchmark_minus_all_series_short.loc[:, ~benchmark_minus_all_series_short.columns.duplicated()]\n",
    "\n",
    "benchmark_minus_indices_mid          = create_spreads(indices_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_sectors_mid          = create_spreads(sectors_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_industries_mid       = create_spreads(industries_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_dia_holdings_mid       = create_spreads(dia_holdings_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_qqq_holdings_mid       = create_spreads(qqq_holdings_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_xlk_holdings_mid       = create_spreads(xlk_holdings_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_xlf_holdings_mid       = create_spreads(xlf_holdings_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_xli_holdings_mid       = create_spreads(xli_holdings_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_xlv_holdings_mid       = create_spreads(xlv_holdings_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_xlu_holdings_mid       = create_spreads(xlu_holdings_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_xlb_holdings_mid       = create_spreads(xlb_holdings_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_xly_holdings_mid       = create_spreads(xly_holdings_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_xlc_holdings_mid       = create_spreads(xlc_holdings_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_xle_holdings_mid       = create_spreads(xle_holdings_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_xlre_holdings_mid       = create_spreads(xlre_holdings_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "benchmark_minus_xlp_holdings_mid      = create_spreads(xlp_holdings_df, benchmark_series, time_frame=time_frame_mid,mode=mode)\n",
    "\n",
    "\n",
    "benchmark_minus_all_series_mid= pd.concat([\n",
    "    benchmark_minus_indices_mid,\n",
    "    benchmark_minus_sectors_mid,\n",
    "    benchmark_minus_industries_mid,\n",
    "    benchmark_minus_dia_holdings_mid,\n",
    "    benchmark_minus_xlk_holdings_mid,\n",
    "    benchmark_minus_xlf_holdings_mid,\n",
    "    benchmark_minus_xli_holdings_mid,\n",
    "    benchmark_minus_xlv_holdings_mid,\n",
    "    benchmark_minus_xlu_holdings_mid,\n",
    "    benchmark_minus_xlb_holdings_mid,\n",
    "    benchmark_minus_xly_holdings_mid,\n",
    "    benchmark_minus_xlc_holdings_mid,\n",
    "    benchmark_minus_xle_holdings_mid,\n",
    "    benchmark_minus_xlre_holdings_mid,\n",
    "    benchmark_minus_xlp_holdings_mid\n",
    "], axis=1)\n",
    "\n",
    "benchmark_minus_all_series_mid =benchmark_minus_all_series_mid.loc[:, ~benchmark_minus_all_series_mid.columns.duplicated()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph: Market Caps\n",
    "plot_market_caps(sp500_info)\n",
    "plot_market_caps(nasdaq_info)\n",
    "plot_market_caps(dow_info)\n",
    "plot_market_caps(xlk_info)\n",
    "plot_market_caps(xlf_info)\n",
    "plot_market_caps(xli_info)\n",
    "plot_market_caps(xlv_info)\n",
    "plot_market_caps(xlu_info)\n",
    "plot_market_caps(xlp_info)\n",
    "plot_market_caps(xlc_info)\n",
    "plot_market_caps(xlb_info)\n",
    "plot_market_caps(xlre_info)\n",
    "plot_market_caps(xle_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0918cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph: Find Oversold Investments relative to Benchmark\n",
    "filtered_assets = filter_assets_by_positive_spread_std(benchmark_minus_all_series_mid)\n",
    "filtered_assets = filtered_assets[filtered_assets]\n",
    "#Create a Plotly Table trace\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=['Date', 'Boolean Value']),\n",
    "    cells=dict(values=[filtered_assets.index, filtered_assets], align='left'))\n",
    "])\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Spreads that are over extended\n",
    "filtered_assets = filter_assets_by_positive_spread_std(benchmark_minus_all_series_mid)\n",
    "filtered_assets = filtered_assets[filtered_assets]\n",
    "# Convert filtered_assets to a DataFrame and reset the index\n",
    "filtered_assets_df = filtered_assets.reset_index()\n",
    "filtered_assets_df.columns = ['Symbol', 'Boolean Value']\n",
    "\n",
    "# Remove any leading or trailing whitespace from symbols\n",
    "filtered_assets_df['Symbol'] = filtered_assets_df['Symbol'].str.strip()\n",
    "\n",
    "# Make a copy of sp500_table\n",
    "sp500_table_copy = sp500_table.copy()\n",
    "\n",
    "# Prefix 'Benchmark_minus_' to symbols in the copy to match the format\n",
    "sp500_table_copy['Symbol'] = 'Benchmark_minus_' + sp500_table_copy['Symbol'].str.strip()\n",
    "\n",
    "# Extract the symbols from filtered_assets_df (no prefix needed)\n",
    "filtered_symbols = filtered_assets_df['Symbol']\n",
    "\n",
    "# Filter the copy of sp500_table based on the updated filtered_assets symbols\n",
    "sp500_filtered = sp500_table_copy[sp500_table_copy['Symbol'].isin(filtered_symbols)]\n",
    "\n",
    "# Merge sp500_filtered with filtered_assets_df (no need to adjust filtered_assets_df)\n",
    "merged_df = sp500_filtered.merge(filtered_assets_df, left_on='Symbol', right_on='Symbol')\n",
    "\n",
    "#add market caps\n",
    "merged_df = pd.merge(merged_df, sp500_info[['Symbol', 'Market Cap']], on='Symbol', how='left')\n",
    "merged_df = merged_df.rename(columns={'Market Cap_x': 'Market Cap'})\n",
    "merged_df.drop(columns=['Market Cap_y'], inplace=True)\n",
    "merged_df = merged_df.sort_values(by='Market Cap', ascending=False)\n",
    "\n",
    "# Create a Plotly Table trace\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(values=['Symbol', 'Sector', 'Sub-Industry', 'Boolean Value', 'Market Cap']),\n",
    "    cells=dict(values=[merged_df['Symbol'], merged_df['Sector'], merged_df['Sub-Industry'], merged_df['Boolean Value'], merged_df['Market Cap']], align='left'))\n",
    "])\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44444b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter extended spreads by sector\n",
    "Sector = 'Industrials'\n",
    "merged_df[merged_df['Sector'] == Sector]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7c814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph: spreads & risk adjusted performance\n",
    "TICKER = 'XLK'\n",
    "SPREAD = 'Benchmark_minus_' + TICKER\n",
    "create_spread_plot(benchmark_minus_all_series_week[SPREAD]).show()\n",
    "create_spread_plot(benchmark_minus_all_series_short[SPREAD]).show()\n",
    "create_spread_plot(benchmark_minus_all_series_mid[SPREAD]).show()\n",
    "plot_risk_adjusted_returns(all_series[TICKER],time_frame_short).show()\n",
    "plot_risk_adjusted_returns(all_series[TICKER],time_frame_mid).show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6defd577cd85e3649e86c46a537635b7104b081260a238509c81cac8b534171b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
