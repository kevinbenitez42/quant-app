{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notebook description:\n",
    "\n",
    "# this notebook is used to evaluate the market of assets and find potential assets to invest in\n",
    "# with the best risk/reward characteristics. This notebook is intented to analyze a broad group of market assets\n",
    "# and does NOT focus on any particular assets. Computing data for a large number of assets is computationally expensive and thus\n",
    "# the analysis is relegated to other notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "#move all the code that you dont need to define in custom functions into the Quantapp library\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import logging\n",
    "logger = logging.getLogger('yfinance')\n",
    "logger.disabled = True\n",
    "logger.propagate = False\n",
    "# Load libraries\n",
    "from Quantapp.Plotter import Plotter\n",
    "from Quantapp.Computation import Computation\n",
    "from Quantapp.EconomicData import EconomicData\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from IPython.display import display\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import holidays\n",
    "import plotly.express as px\n",
    "import concurrent.futures\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#shut down warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "time_frame_week = 7\n",
    "time_frame_short = 21\n",
    "time_frame_mid   = 50\n",
    "time_frame_long = 200\n",
    "interval = '1d'\n",
    "period     = '10y'\n",
    "\n",
    "risk_free_rate = 0.02 / 252  # Annualized risk-free rate divided by trading days\n",
    "benchmark = 'SPY'\n",
    "\n",
    "qc = Computation()\n",
    "qp = Plotter()\n",
    "qe = EconomicData()\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load custom functions\n",
    "\n",
    "def create_sortino_negative_indicators(sortino_diff_50, sortino_diff_200):\n",
    "    \"\"\"\n",
    "    Creates a DataFrame indicating whether the latest Sortino ratio difference for each ticker is less than zero\n",
    "    for 21-day, 50-day, and 200-day rolling windows.\n",
    "\n",
    "    Parameters:\n",
    "        sortino_diff_21 (pd.DataFrame): DataFrame of 21-day Sortino differences.\n",
    "        sortino_diff_50 (pd.DataFrame): DataFrame of 50-day Sortino differences.\n",
    "        sortino_diff_200 (pd.DataFrame): DataFrame of 200-day Sortino differences.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with tickers as rows and columns ['21_Day', '50_Day', '200_Day'],\n",
    "                      with True indicating the latest Sortino difference is <0, and False otherwise.\n",
    "    \"\"\"\n",
    "    # Extract the latest row from each Sortino difference DataFrame\n",
    "    latest_50 = sortino_diff_50.iloc[-1]\n",
    "    latest_200 = sortino_diff_200.iloc[-1]\n",
    "\n",
    "    # Create a new DataFrame with indicators\n",
    "    indicators_df = pd.DataFrame({\n",
    "        '50_Day': latest_50 > 0,\n",
    "        '200_Day': latest_200 > 0\n",
    "    })\n",
    "\n",
    "    # Reset index to have tickers as a column\n",
    "    indicators_df = indicators_df.reset_index()\n",
    "    indicators_df.columns = ['Ticker',  'Relative performance: 50 Day Sortino (Benchmark - asset)', 'Relative performance: 200 Day Sortino (Benchmark - asset)']\n",
    "\n",
    "    return indicators_df\n",
    "\n",
    "def calculate_z_scores(rolling_sortino_ratio):\n",
    "    \"\"\"\n",
    "    Calculates the z-scores for the latest row of the rolling Sortino ratio DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        rolling_sortino_ratio (pd.DataFrame): DataFrame of rolling Sortino ratios, with tickers as columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A Series of z-scores for the latest values.\n",
    "    \"\"\"\n",
    "    mean = rolling_sortino_ratio.mean()\n",
    "    std = rolling_sortino_ratio.std()\n",
    "    latest_values = rolling_sortino_ratio.iloc[-1]\n",
    "    z_scores = (latest_values - mean) / std\n",
    "    return z_scores\n",
    "\n",
    "def categorize_z_score(z):\n",
    "    \"\"\"\n",
    "    Categorizes a z-score into integer buckets.\n",
    "\n",
    "    Integer categories (based on z-score):\n",
    "      3  => z > 3\n",
    "      2  => 2 < z <= 3\n",
    "      1  => 1 < z <= 2\n",
    "      0  => -1 < z <= 1\n",
    "     -1  => -2 < z <= -1\n",
    "     -2  => -3 < z <= -2\n",
    "     -3  => z <= -3\n",
    "\n",
    "    Parameters:\n",
    "        z (float): The z-score to categorize.\n",
    "\n",
    "    Returns:\n",
    "        int: The integer category.\n",
    "    \"\"\"\n",
    "    if z > 3:\n",
    "        return 3\n",
    "    elif z > 2:\n",
    "        return 2\n",
    "    elif z > 1:\n",
    "        return 1\n",
    "    elif z > -1:\n",
    "        return 0\n",
    "    elif z > -2:\n",
    "        return -1\n",
    "    elif z > -3:\n",
    "        return -2\n",
    "    else:\n",
    "        return -3\n",
    "\n",
    "def create_sortino_std_deviation_table(rolling_sortino_ratio):\n",
    "    \"\"\"\n",
    "    Creates a DataFrame indicating how many standard deviations the latest Sortino ratio \n",
    "    for each ticker is above or below its historical mean, using integer buckets.\n",
    "\n",
    "    Parameters:\n",
    "        rolling_sortino_ratio (pd.DataFrame): DataFrame containing the rolling \n",
    "                                                Sortino ratios for each ticker.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'Ticker' and 'Std Dev Direction' columns.\n",
    "    \"\"\"\n",
    "    # Obtain the z-scores using the separated function\n",
    "    z_scores = calculate_z_scores(rolling_sortino_ratio)\n",
    "    # Categorize each z-score using the separate categorize_z_score function\n",
    "    categories = z_scores.apply(categorize_z_score)\n",
    "\n",
    "    # Create and return the deviation table DataFrame\n",
    "    deviation_table = pd.DataFrame({\n",
    "        'Ticker': rolling_sortino_ratio.columns.tolist(),\n",
    "        'Std Dev Direction': categories.tolist()\n",
    "    })\n",
    "\n",
    "    return deviation_table\n",
    "\n",
    "def create_price_std_deviation_table(price_data, window_sizes=[21, 50, 200]):\n",
    "    \"\"\"\n",
    "    Creates a DataFrame indicating how many standard deviations the latest price is\n",
    "    above or below its rolling mean over specified window sizes, using integer buckets.\n",
    "\n",
    "    Integer categories (based on z-score):\n",
    "      3  => z > 3\n",
    "      2  => 2 < z <= 3\n",
    "      1  => 1 < z <= 2\n",
    "      0  => -1 < z <= 1\n",
    "     -1  => -2 < z <= -1\n",
    "     -2  => -3 < z <= -2\n",
    "     -3  => z <= -3\n",
    "    \"\"\"\n",
    "    # Initialize dictionary to store deviation categories\n",
    "    deviation_data = {'Ticker': price_data.columns.tolist()}\n",
    "\n",
    "    for window in window_sizes:\n",
    "        categories = []\n",
    "        for ticker in price_data.columns:\n",
    "            ticker_prices = price_data[ticker].dropna()\n",
    "            if len(ticker_prices) >= window:\n",
    "                rolling_mean = ticker_prices.rolling(window=window).mean()\n",
    "                rolling_std = ticker_prices.rolling(window=window).std()\n",
    "\n",
    "                latest_price = ticker_prices.iloc[-1]\n",
    "                latest_mean = rolling_mean.iloc[-1]\n",
    "                latest_std = rolling_std.iloc[-1]\n",
    "\n",
    "                if latest_std == 0 or pd.isna(latest_std):\n",
    "                    category = 'Insufficient Data'\n",
    "                else:\n",
    "                    z_score = (latest_price - latest_mean) / latest_std\n",
    "\n",
    "                    def categorize_z(z):\n",
    "                        if z > 3:\n",
    "                            return 3\n",
    "                        elif z > 2:\n",
    "                            return 2\n",
    "                        elif z > 1:\n",
    "                            return 1\n",
    "                        elif z > -1:\n",
    "                            return 0\n",
    "                        elif z > -2:\n",
    "                            return -1\n",
    "                        elif z > -3:\n",
    "                            return -2\n",
    "                        else:\n",
    "                            return -3\n",
    "\n",
    "                    category = categorize_z(z_score)\n",
    "            else:\n",
    "                category = 'Insufficient Data'\n",
    "            categories.append(category)\n",
    "        deviation_data[f'Std Dev Direction for {window}_Day Price'] = categories\n",
    "\n",
    "    deviation_table = pd.DataFrame(deviation_data)\n",
    "    return deviation_table\n",
    "\n",
    "def plot_combined_table(df, title='Combined Sortino Indicators'):\n",
    "    \"\"\"\n",
    "    Plots a combined table with indicators for Sortino differences and standard deviation categories,\n",
    "    highlighting the direction of deviations (positive or negative).\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Combined DataFrame with 'Ticker', Sortino differences, and deviation categories.\n",
    "        title (str): Title of the table.\n",
    "    \"\"\"\n",
    "    # Define color mappings for positive and negative deviations\n",
    "    positive_deviation_colors = {\n",
    "        '>+3 SD': 'lightgreen',\n",
    "        '+2-3 SD': 'yellow',\n",
    "        '+1-2 SD': 'orange',\n",
    "        '+<1 SD': 'white'\n",
    "    }\n",
    "    \n",
    "    negative_deviation_colors = {\n",
    "        '<-3 SD': 'lightcoral',\n",
    "        '-2-3 SD': 'coral',\n",
    "        '-1-2 SD': 'lightblue',\n",
    "        '-<1 SD': 'white'\n",
    "    }\n",
    "    \n",
    "    # Initialize fill colors based on deviation categories and Sortino differences\n",
    "    fill_colors = []\n",
    "    for _, row in df.iterrows():\n",
    "        row_colors = []\n",
    "        for col in df.columns:\n",
    "            if col == 'Ticker':\n",
    "                row_colors.append('lightgrey')  # Default color for Ticker column\n",
    "            elif 'Relative performance' in col:\n",
    "                if row[col]:  # Underperforming if True\n",
    "                    row_colors.append('lightgreen')  # Highlight underperforming assets\n",
    "                else:\n",
    "                    row_colors.append('white')        # Default color\n",
    "            else:\n",
    "                deviation = row[col]\n",
    "                if deviation.startswith('+'):\n",
    "                    # Positive Deviation\n",
    "                    color = positive_deviation_colors.get(deviation, 'white')\n",
    "                elif deviation.startswith('-'):\n",
    "                    # Negative Deviation\n",
    "                    color = negative_deviation_colors.get(deviation, 'white')\n",
    "                else:\n",
    "                    color = 'white'  # Default color for any other case\n",
    "                row_colors.append(color)\n",
    "        fill_colors.append(row_colors)\n",
    "    \n",
    "    # Transpose fill_colors to match Plotly's column-wise format\n",
    "    fill_colors_transposed = list(map(list, zip(*fill_colors)))\n",
    "    \n",
    "    # Replace boolean values with descriptive text for Sortino differences\n",
    "    display_df = df.copy()\n",
    "    for col in df.columns:\n",
    "        if 'Relative performance' in col:\n",
    "            display_df[col] = display_df[col].apply(lambda x: 'Underperforming' if x else 'Overperforming')\n",
    "    \n",
    "    # Create the Plotly table\n",
    "    fig = go.Figure(data=[go.Table(\n",
    "        header=dict(\n",
    "            values=['<b>' + col.replace('_', ' ') + '</b>' for col in display_df.columns],\n",
    "            fill_color='paleturquoise',\n",
    "            align='center',\n",
    "            font=dict(color='black', size=12)\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[display_df[col] for col in display_df.columns],\n",
    "            fill_color=fill_colors_transposed,\n",
    "            align='center',\n",
    "            font=dict(color='black', size=11)\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    # Update layout for aesthetics\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        template='plotly_white',\n",
    "        height=800,\n",
    "        margin=dict(l=50, r=50, t=80, b=200)  # Increased bottom margin for legend\n",
    "    )\n",
    "    \n",
    "    # Add a comprehensive legend using annotations\n",
    "    legend_text = (\n",
    "        \"<b>Legend:</b><br>\"\n",
    "        \"<b>Deviation Directions:</b><br>\"\n",
    "        \"Light Green: >+3 SD (Significantly Above Mean)<br>\"\n",
    "        \"Yellow: +2-3 SD (Above Mean)<br>\"\n",
    "        \"Orange: +1-2 SD (Slightly Above Mean)<br>\"\n",
    "        \"Light Coral: <-3 SD (Significantly Below Mean)<br>\"\n",
    "        \"Coral: -2-3 SD (Below Mean)<br>\"\n",
    "        \"Light Blue: -1-2 SD (Slightly Below Mean)<br>\"\n",
    "        \"White: Within 1 SD<br><br>\"\n",
    "        \"<b>Performance Indicators:</b><br>\"\n",
    "        \"Light Green: Underperforming<br>\"\n",
    "        \"White: Overperforming\"\n",
    "    )\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        text=legend_text,\n",
    "        showarrow=False,\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.5, y=-0.3,\n",
    "        xanchor='center',\n",
    "        yanchor='top',\n",
    "        font=dict(color='black', size=12)\n",
    "    )\n",
    "    \n",
    "    # Show the table\n",
    "    fig.show()\n",
    "\n",
    "def compute_rolling_sortino_ratios(df, n, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    Computes the rolling \"n\" day Sortino ratios for a DataFrame of stock prices.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing stock prices with ticker symbols as columns.\n",
    "        n (int): The window size for the rolling calculation.\n",
    "        risk_free_rate (float): The risk-free rate for the Sortino ratio calculation (default is 0.0).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the rolling \"n\" day Sortino ratios for each ticker symbol.\n",
    "    \"\"\"\n",
    "    # Calculate daily returns\n",
    "    returns = df.pct_change()\n",
    "\n",
    "    # Calculate excess returns\n",
    "    excess_returns = returns - risk_free_rate / 252\n",
    "\n",
    "    # Calculate downside deviation\n",
    "    def downside_deviation(x):\n",
    "        negative_returns = x[x < 0]\n",
    "        return np.sqrt((negative_returns ** 2).mean())\n",
    "\n",
    "    rolling_downside_dev = excess_returns.rolling(window=n).apply(downside_deviation, raw=False)\n",
    "\n",
    "    # Calculate rolling mean of excess returns\n",
    "    rolling_mean_excess_returns = excess_returns.rolling(window=n).mean()\n",
    "    \n",
    "    # Calculate rolling Sortino ratio\n",
    "    rolling_sortino_ratio = rolling_mean_excess_returns / rolling_downside_dev\n",
    "\n",
    "    return rolling_sortino_ratio\n",
    "\n",
    "def compute_rolling_sortino_ratios_benchmark_minus_asset(df,benchmark_ticker, n, risk_free_rate=0.0):\n",
    "    \"\"\"\n",
    "    Computes the rolling \"n\" day Sortino ratios for a DataFrame of stock prices.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing stock prices with ticker symbols as columns.\n",
    "        n (int): The window size for the rolling calculation.\n",
    "        risk_free_rate (float): The risk-free rate for the Sortino ratio calculation (default is 0.0).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the rolling \"n\" day Sortino ratios for each ticker symbol.\n",
    "    \"\"\"\n",
    "    # Calculate daily returns\n",
    "    returns = df.pct_change()\n",
    "\n",
    "    # Calculate excess returns\n",
    "    excess_returns = returns - risk_free_rate / 252\n",
    "\n",
    "    # Calculate downside deviation\n",
    "    def downside_deviation(x):\n",
    "        negative_returns = x[x < 0]\n",
    "        return np.sqrt((negative_returns ** 2).mean())\n",
    "\n",
    "    rolling_downside_dev = excess_returns.rolling(window=n).apply(downside_deviation, raw=False)\n",
    "\n",
    "    # Calculate rolling mean of excess returns\n",
    "    rolling_mean_excess_returns = excess_returns.rolling(window=n).mean()\n",
    "    \n",
    "    # Calculate rolling Sortino ratio\n",
    "    rolling_sortino_ratio = rolling_mean_excess_returns / rolling_downside_dev\n",
    "    \n",
    "    benchmark_sortino = rolling_sortino_ratio[benchmark_ticker]\n",
    "    rolling_sortino_ratio = rolling_sortino_ratio.sub(benchmark_sortino, axis=0)\n",
    "    benchmark_minus_asset = -rolling_sortino_ratio\n",
    "    rolling_sortino_ratio = benchmark_minus_asset\n",
    "    #rolling_sortino_ratio.columns = ['Benchmark_Minus_' + col for col in rolling_sortino_ratio.columns]\n",
    "\n",
    "    return rolling_sortino_ratio\n",
    "\n",
    "def simplify_datetime_index(series):\n",
    "    \"\"\"\n",
    "    Simplifies the DateTime index of a Series to contain only the date (YYYY-MM-DD),\n",
    "    maintaining it as a DateTimeIndex without timezone information.\n",
    "    \n",
    "    Parameters:\n",
    "        series (pd.Series): The input Series with a DateTimeIndex.\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: The Series with the DateTime index simplified to YYYY-MM-DD.\n",
    "    \"\"\"\n",
    "    if not isinstance(series.index, pd.DatetimeIndex):\n",
    "        raise TypeError(\"The Series index must be a DateTimeIndex.\")\n",
    "    \n",
    "    # Remove timezone information if present\n",
    "    if series.index.tz is not None:\n",
    "        series = series.copy()\n",
    "        series.index = series.index.tz_convert('UTC').tz_localize(None)\n",
    "    \n",
    "    # Normalize the index to remove the time component\n",
    "    series.index = series.index.normalize()\n",
    "    \n",
    "    return series\n",
    "\n",
    "def plot_time_series(all_series, time_frame='1y', title='Time Series Data of Ticker Symbols'):\n",
    "    \"\"\"\n",
    "    Plots the time series data for a DataFrame where each column is a ticker symbol and each row is a price.\n",
    "\n",
    "    Parameters:\n",
    "        all_series (pd.DataFrame): DataFrame containing time series data with ticker symbols as columns and prices as rows.\n",
    "        title (str): Title for the plot (default is 'Time Series Data of Ticker Symbols').\n",
    "    \"\"\"\n",
    "    # Filter out the data based on the specified time frame\n",
    "    if time_frame == '1y':\n",
    "        all_series = all_series.loc[all_series.index >= all_series.index[-1] - pd.DateOffset(years=1)]\n",
    "    elif time_frame == '3y':\n",
    "        all_series = all_series.loc[all_series.index >= all_series.index[-1] - pd.DateOffset(years=3)]\n",
    "    elif time_frame == '5y':\n",
    "        all_series = all_series.loc[all_series.index >= all_series.index[-1] - pd.DateOffset(years=5)]\n",
    "    elif time_frame == '10y':\n",
    "        all_series = all_series.loc[all_series.index >= all_series.index[-1] - pd.DateOffset(years=10)]\n",
    "    else:\n",
    "        # Error handling for invalid time frame\n",
    "        print(\"Error: Invalid time frame\")\n",
    "        return\n",
    "    \n",
    "    # Create a Plotly figure\n",
    "    fig = px.line(all_series, title=title)\n",
    "    \n",
    "    # Add a dashed horizontal line at zero\n",
    "    fig.add_hline(y=0, line_dash='dash', line_color='red')\n",
    "    \n",
    "    # Update layout for the figure\n",
    "    fig.update_layout(\n",
    "        xaxis_title='Date',\n",
    "        yaxis_title='Price',\n",
    "        template='plotly_dark',\n",
    "        xaxis=dict(\n",
    "            tickangle=-45,\n",
    "            showgrid=True,\n",
    "            zeroline=True  # Add zero line for x-axis\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showgrid=True,\n",
    "            zeroline=True  # Add zero line for y-axis\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "    \n",
    "def generate_series(tickers, columns=['Adj Close', 'Close', 'High', 'Low', 'Open', 'Volume'], period=period, interval=interval):\n",
    "    \"\"\"\n",
    "    Generate a DataFrame or Series containing the specified columns for the given tickers.\n",
    "\n",
    "    Parameters:\n",
    "    - tickers: List of ticker symbols or a single ticker symbol.\n",
    "    - columns: List of columns to retrieve or a single column to retrieve (default is ['Close']).\n",
    "    - period: Data period to retrieve (default is '1y').\n",
    "    - interval: Data interval to retrieve (default is '1d').\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame or pd.Series with the specified columns for the given tickers.\n",
    "    \"\"\"\n",
    "    # Ensure tickers and columns are lists\n",
    "    if isinstance(tickers, str):\n",
    "        tickers = [tickers]\n",
    "    if isinstance(columns, str):\n",
    "        columns = [columns]\n",
    "\n",
    "    tickers = [ticker.replace('.', '-') for ticker in tickers]\n",
    "    try:\n",
    "        df = yf.download(tickers, period=period, interval=interval, progress=False)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Check if the specified columns exist in the DataFrame\n",
    "    missing_columns = [col for col in columns if col not in df.columns.get_level_values(0)]\n",
    "    if missing_columns:\n",
    "        print(f\"Error: The following columns are not available: {missing_columns}\")\n",
    "        print(f\"Possible columns are: {df.columns.get_level_values(0).unique().tolist()}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = df[columns]\n",
    "    \n",
    "    # Handle the case where there is only one ticker and one column\n",
    "    if len(tickers) == 1 and len(columns) == 1:\n",
    "        return df[columns[0]].rename(tickers[0].replace('-', '.'))\n",
    "    \n",
    "    # Handle the case where there is only one ticker\n",
    "    if len(tickers) == 1:\n",
    "        df.columns = [col.replace('-', '.') for col in df.columns]\n",
    "    else:\n",
    "        # If only one column is selected, return a DataFrame with tickers as column names\n",
    "        if len(columns) == 1:\n",
    "            df = df[columns[0]]\n",
    "            df.columns = [col.replace('-', '.') for col in df.columns]\n",
    "        else:\n",
    "            # Flatten the multi-level columns if multiple tickers are requested\n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df.columns = pd.MultiIndex.from_tuples([(col[1], col[0]) for col in df.columns.values])\n",
    "            else:\n",
    "                df.columns = pd.MultiIndex.from_tuples([(col.split('.')[0], col.split('.')[1]) for col in df.columns])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_assets_by_positive_spread_std(asset_spreads):\n",
    "    spreads = asset_spreads\n",
    "    positive_spreads = spreads[spreads >= 0] \n",
    "    \n",
    "    mean = positive_spreads.mean()\n",
    "    std_dev = positive_spreads.std()\n",
    "\n",
    "    latest_spread = spreads.iloc[-1]\n",
    "    threshold = mean + std_dev\n",
    "\n",
    "    return latest_spread>=threshold\n",
    "\n",
    "def filter_assets_below_negative_std(asset_spreads):\n",
    "    if not isinstance(asset_spreads, pd.Series):\n",
    "        raise TypeError(\"asset_spreads must be a pandas Series\")\n",
    "\n",
    "    negative_spreads = asset_spreads[asset_spreads < 0]\n",
    "    if negative_spreads.empty:\n",
    "        return pd.Series(dtype=bool)  \n",
    "    \n",
    "    mean_negative = negative_spreads.mean()\n",
    "    std_dev_negative = negative_spreads.std()\n",
    "\n",
    "    threshold_negative = mean_negative - 0.75 * std_dev_negative\n",
    "    return asset_spreads < threshold_negative\n",
    "\n",
    "def get_sector_info(ticker):\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        sector = stock.info.get('sector', 'N/A')\n",
    "        sub_industry = stock.info.get('industry', 'N/A')\n",
    "        return {'Ticker': ticker, 'Sector': sector, 'Sub-Industry': sub_industry}\n",
    "    except Exception as e:\n",
    "        #print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return {'Ticker': ticker, 'Sector': 'N/A', 'Sub-Industry': 'N/A'}\n",
    "\n",
    "def fetch_ticker_info(ticker):\n",
    "    info = get_sector_info(ticker)\n",
    "    print(info)\n",
    "    print(yf.Ticker(ticker).info)\n",
    "    #market_cap = yf.Ticker(ticker).info.get('marketCap')\n",
    "    #return info['Sector'], info['Sub-Industry'], market_cap\n",
    "\n",
    "def get_market_caps(table):\n",
    "    #print(\"Starting market cap retrieval process...\")\n",
    "    \n",
    "    tickers = table['Symbol'].tolist()\n",
    "    #print(f\"Original tickers: {tickers[:10]}...\")  # Print first 10 for brevity\n",
    "\n",
    "    # Optimize ticker adjustment\n",
    "    tickers = ['BRK-B' if symbol == 'BRK.B' else 'BF-B' if symbol == 'BF.B' else symbol for symbol in tickers]\n",
    "    #print(f\"Adjusted tickers: {tickers[:10]}...\")  # Print first 10 for brevity\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(executor.map(fetch_ticker_info, tickers))\n",
    "\n",
    "    # Unpack results\n",
    "    sectors, sub_industries, market_caps = zip(*results)\n",
    "\n",
    "    table['Sector'] = sectors\n",
    "    table['Sub-Industry'] = sub_industries\n",
    "    table['Market Cap'] = market_caps\n",
    "    \n",
    "    #print(\"Market cap retrieval process completed.\")\n",
    "    return table\n",
    "\n",
    "def get_market_cap_threshold_companies(info):\n",
    "    \"\"\"\n",
    "    Calculates market cap rankings and identifies companies contributing to specified cumulative market cap thresholds.\n",
    "\n",
    "    Parameters:\n",
    "        info (pd.DataFrame): DataFrame containing at least 'Symbol' and 'Market Cap' columns.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are threshold labels (e.g., 'Top 50%') and values are lists of company dictionaries\n",
    "              containing 'Symbol', 'Market Cap', 'Market Cap %', 'Cumulative Market Cap %', and 'Rank'.\n",
    "    \"\"\"\n",
    "    # Step 1: Create a DataFrame of market caps\n",
    "    market_caps = pd.DataFrame(info[['Symbol', 'Market Cap']])\n",
    "    \n",
    "    # Step 2: Sort companies by market cap in descending order\n",
    "    market_caps = market_caps.sort_values(by='Market Cap', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Step 3: Calculate total market cap\n",
    "    total_market_cap = market_caps['Market Cap'].sum()\n",
    "\n",
    "    # Step 4: Calculate individual Market Cap %\n",
    "    market_caps['Market Cap %'] = (market_caps['Market Cap'] / total_market_cap) * 100\n",
    "\n",
    "    # Step 5: Calculate cumulative Market Cap %\n",
    "    market_caps['Cumulative Market Cap %'] = market_caps['Market Cap %'].cumsum()\n",
    "\n",
    "    # Step 6: Assign Rank\n",
    "    market_caps['Rank'] = market_caps.index + 1\n",
    "\n",
    "    # Step 7: Define thresholds\n",
    "    thresholds = [50, 80]  # You can adjust or add more thresholds as needed\n",
    "    threshold_dict = {}\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        # Find the first index where cumulative market cap meets or exceeds the threshold\n",
    "        idx = market_caps[market_caps['Cumulative Market Cap %'] >= threshold].index[0]\n",
    "\n",
    "        # Select companies up to that index\n",
    "        companies = market_caps.loc[:idx, ['Symbol', 'Market Cap', 'Market Cap %', 'Cumulative Market Cap %', 'Rank']]\n",
    "\n",
    "        # Convert to list of dictionaries\n",
    "        companies_list = companies.to_dict('records')\n",
    "\n",
    "        # Add to the threshold dictionary with appropriate key\n",
    "        threshold_key = f'Top {threshold}%'\n",
    "        threshold_dict[threshold_key] = companies_list\n",
    "\n",
    "    return threshold_dict\n",
    "\n",
    "def remove_weekends_and_holidays(df, country='US'):\n",
    "    \"\"\"\n",
    "    Removes weekend and holiday rows from a DataFrame with a DateTime index.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with DateTime index.\n",
    "        country (str): Country code for holidays. Default is 'US'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame without weekend and holiday data.\n",
    "    \"\"\"\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise TypeError(\"DataFrame index must be a DateTimeIndex\")\n",
    "\n",
    "    # Remove weekends\n",
    "    df_weekdays = df[df.index.dayofweek < 5]\n",
    "\n",
    "    # Get holidays\n",
    "    country_holidays = holidays.CountryHoliday(country)\n",
    "\n",
    "    # Remove holidays\n",
    "    df_clean = df_weekdays[~df_weekdays.index.normalize().isin(country_holidays)]\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "mode='standard'\n",
    "\n",
    "def create_and_concat_spreads(dataframes, benchmark_series, time_frame, mode):\n",
    "    benchmark_spreads = [\n",
    "        qc.create_spreads(df, benchmark_series, time_frame=time_frame, mode=mode)\n",
    "        for df in dataframes\n",
    "    ]\n",
    "    combined_spreads = pd.concat(benchmark_spreads, axis=1)\n",
    "    combined_spreads = combined_spreads.loc[:, ~combined_spreads.columns.duplicated()]\n",
    "    return combined_spreads\n",
    "\n",
    "\n",
    "def create_pairwise_spreads(etf_dataframes, window=20):\n",
    "    \"\"\"\n",
    "    Creates pairwise spreads of rolling returns between assets within each category.\n",
    "    \n",
    "    Parameters:\n",
    "        etf_dataframes (dict): Dictionary of DataFrames where each key is a category \n",
    "                              and values are DataFrames with ticker columns\n",
    "        window (int): Rolling window period for calculating returns (default=20)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary where keys match the input categories and values are DataFrames\n",
    "              containing the spreads between rolling returns of unique asset pairs\n",
    "    \"\"\"\n",
    "    pairwise_spreads = {}\n",
    "\n",
    "    for category, df in etf_dataframes.items():\n",
    "        # Skip categories with only one asset\n",
    "        if df.shape[1] <= 1:\n",
    "            continue\n",
    "            \n",
    "        # Get valid tickers in this category (those without all NaN values)\n",
    "        valid_tickers = [ticker for ticker in df.columns if not df[ticker].isna().all()]\n",
    "        \n",
    "        if len(valid_tickers) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Create an empty DataFrame for this category's spreads\n",
    "        category_spreads = pd.DataFrame(index=df.index)\n",
    "        \n",
    "        # For each unique pair of tickers, compute the spread of rolling returns\n",
    "        for i in range(len(valid_tickers)):\n",
    "            for j in range(i+1, len(valid_tickers)):  # Start from i+1 to avoid duplicates\n",
    "                ticker1, ticker2 = valid_tickers[i], valid_tickers[j]\n",
    "                \n",
    "                # Find valid data for both assets\n",
    "                valid_data = df[[ticker1, ticker2]].dropna()\n",
    "                if valid_data.empty:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate rolling returns for both assets\n",
    "                returns1 = df[ticker1].pct_change(window)\n",
    "                returns2 = df[ticker2].pct_change(window)\n",
    "                \n",
    "                # Calculate and store the spread between rolling returns\n",
    "                spread_name = f\"{ticker1}-{ticker2}\"\n",
    "                category_spreads[spread_name] = returns1 - returns2\n",
    "        \n",
    "        # Store only if we have valid spreads\n",
    "        if not category_spreads.empty:\n",
    "            pairwise_spreads[category] = category_spreads\n",
    "    \n",
    "    return pairwise_spreads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load: retrieve all tickers / prices \n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# Load: retrieve all tickers / prices / spreads for major markets\n",
    "sp500 = yf.download('SPY', period=period, interval=interval,progress=False)\n",
    "risk_free_rate = yf.download('^IRX', period=period, interval=interval, progress=False)\n",
    "market_assets = qe.get_market_assets()\n",
    "\n",
    "#Load: retrieve prices\n",
    "indices_df             = generate_series(market_assets['INDICES'], columns=['Close'])\n",
    "sectors_df            = generate_series(market_assets['SECTORS'], columns=['Close'])\n",
    "industries_df         = generate_series(market_assets['INDUSTRIES'], columns=['Close'])\n",
    "bonds_df = generate_series(market_assets['BONDS'], columns=['Close'])\n",
    "precious_metals_df = generate_series(market_assets['PRECIOUS_METALS'], columns=['Close'])\n",
    "crypto_df = generate_series(market_assets['CRYPTO'], columns=['Close'])\n",
    "#crypto_df = crypto_df.loc[sp500.index]\n",
    "energy_df = generate_series(market_assets['ENERGY'], columns=['Close'])\n",
    "foreign_markets_df = generate_series(market_assets['FOREIGN_MARKETS'], columns=['Close'])\n",
    "primary_sector_etfs_df = generate_series(market_assets['PRIMARY_SECTORS'], columns=['Close'])\n",
    "major_currency_pairs_df = generate_series(market_assets['MAJOR_CURRENCY_PAIRS'], columns=['Close'])\n",
    "minor_currency_pairs_df = generate_series(market_assets['MINOR_CURRENCY_PAIRS'], columns=['Close'])\n",
    "exotic_currency_pairs_df = generate_series(market_assets['EXOTIC_CURRENCY_PAIRS'], columns=['Close'])\n",
    "cross_currency_pairs_df = generate_series(market_assets['CROSS_CURRENCY_PAIRS'], columns=['Close']) \n",
    "#major_currency_pairs_df = major_currency_pairs_df.loc[sp500.index]\n",
    "#minor_currency_pairs_df = minor_currency_pairs_df.loc[sp500.index]\n",
    "#exotic_currency_pairs_df = exotic_currency_pairs_df.loc[sp500.index]\n",
    "#cross_currency_pairs_df = cross_currency_pairs_df.loc[sp500.index]\n",
    "capitalizations_df = generate_series(market_assets['CAPITALIZATIONS'], columns=['Close'])\n",
    "innovation_df = generate_series(market_assets['INNOVATION'], columns=['Close'])\n",
    "long_leveraged_df = generate_series(market_assets['LONG_LEVERAGE'], columns=['Close'])\n",
    "short_leveraged_df = generate_series(market_assets['SHORT_LEVERAGE'], columns=['Close'])\n",
    "single_factor_df = generate_series(market_assets['SINGLE_FACTOR'], columns=['Close'])\n",
    "multi_factor_df = generate_series(market_assets['MULTI_FACTOR'], columns=['Close'])\n",
    "minimum_volatility_df = generate_series(market_assets['MINIMUM_VOLATILITY'], columns=['Close'])\n",
    "\n",
    "\n",
    "etf_prices = pd.concat([\n",
    "    indices_df,\n",
    "    sectors_df,\n",
    "    industries_df,\n",
    "    bonds_df,\n",
    "    precious_metals_df,\n",
    "#    crypto_df,\n",
    "    energy_df,\n",
    "    foreign_markets_df,\n",
    "    primary_sector_etfs_df,\n",
    "#    major_currency_pairs_df,\n",
    "#    minor_currency_pairs_df,\n",
    "#    exotic_currency_pairs_df,\n",
    "    cross_currency_pairs_df,\n",
    "    capitalizations_df,\n",
    "    innovation_df,\n",
    "    long_leveraged_df,\n",
    "    short_leveraged_df,\n",
    "    single_factor_df,\n",
    "    multi_factor_df,\n",
    "    minimum_volatility_df\n",
    "], axis=1).loc[:, lambda df: ~df.columns.duplicated()]\n",
    "\n",
    "benchmark_series           = etf_prices[benchmark]\n",
    "\n",
    "# List of dataframes for week and short time frames\n",
    "etf_dataframes = {\n",
    "    \"indices\": indices_df, \n",
    "    \"sectors\": sectors_df, \n",
    "    \"industries\": industries_df, \n",
    "    \"bonds\": bonds_df, \n",
    "    \"precious_metals\": precious_metals_df, \n",
    "   # \"crypto\": crypto_df, \n",
    "    \"energy\": energy_df,\n",
    "    \"foreign_markets\": foreign_markets_df, \n",
    "    \"primary_sector_etfs\": primary_sector_etfs_df, \n",
    " #   \"major_currency_pairs\": major_currency_pairs_df, \n",
    " #   \"minor_currency_pairs\": minor_currency_pairs_df, \n",
    " #   \"exotic_currency_pairs\": exotic_currency_pairs_df, \n",
    " #   \"cross_currency_pairs\": cross_currency_pairs_df, \n",
    "    \"capitalizations\": capitalizations_df, \n",
    "    \"innovation\": innovation_df,\n",
    "    \"long_leveraged\": long_leveraged_df,\n",
    "    \"short_leveraged\": short_leveraged_df,\n",
    "    \"single_factor\": single_factor_df,\n",
    "    \"multi_factor\": multi_factor_df,\n",
    "    \"minimum_volatility\": minimum_volatility_df\n",
    "}\n",
    "\n",
    "print('Computing the correlation matrix...')\n",
    "etf_dataframes_correlation_matrices = {key: value.corr() for key, value in etf_dataframes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computations...\n",
    "\n",
    "#1. return spreads between benchmark and all assets\n",
    "#2. the sortino ratios for all assets\n",
    "#3. the spreads between the sortino ratios of all assets and the benchmark\n",
    "\n",
    "print(\"Computing spreads between benchmark and all assets...\")\n",
    "#compute the weekly, short, mid, and long term returns for the benchmark\n",
    "sp500_monthly_returns = qc.calculate_returns(sp500,frequency='monthly')\n",
    "sp500_weekly_returns = qc.calculate_returns(sp500,frequency='weekly')\n",
    "sp500_daily_returns = qc.calculate_returns(sp500,frequency='daily')\n",
    "\n",
    "\n",
    "#etf_dataframes to list\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "#the spreads between the benchmark and all assets\n",
    "#Calculate: spreads\n",
    "\n",
    "\n",
    "print(\"Computing spreads between benchmark and all assets...\")\n",
    "# Create and concatenate spreads for the weekly time frame\n",
    "benchmark_minus_etf_week = create_and_concat_spreads(\n",
    "    list(etf_dataframes.values()), benchmark_series, time_frame=time_frame_week, mode=mode\n",
    ")\n",
    "\n",
    "print(f\"Computing spreads between benchmark and all assets for the short time frame ({time_frame_short} days)...\")\n",
    "# Create and concatenate spreads for the short time frame\n",
    "benchmark_minus_etf_short = create_and_concat_spreads(\n",
    "    list(etf_dataframes.values()), benchmark_series, time_frame=time_frame_short, mode=mode\n",
    ")\n",
    "\n",
    "print(f\"Computing spreads between benchmark and all assets for the mid time frame ({time_frame_mid} days)...\")\n",
    "benchmark_minus_etf_mid = create_and_concat_spreads(\n",
    "    list(etf_dataframes.values()), benchmark_series, time_frame=time_frame_mid, mode=mode\n",
    ")\n",
    "\n",
    "print(f\"Computing spreads between benchmark and all assets for the long time frame ({time_frame_long} days)...\")\n",
    "benchmark_minus_etf_long = create_and_concat_spreads(\n",
    "    list(etf_dataframes.values()), benchmark_series, time_frame=time_frame_long, mode=mode\n",
    ")\n",
    "print(\" \")\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "#the sortino ratios for all assets\n",
    "print(f\"computing the rolling sortino ratios for all assets for the short time frame ({time_frame_short} days)...\")\n",
    "rolling_sortino_ratios_etf_21 = compute_rolling_sortino_ratios(etf_prices, n=21)\n",
    "\n",
    "print(f\"computing the rolling sortino ratios for all assets for the mid time frame ({time_frame_mid} days)...\")\n",
    "rolling_sortino_ratios_etf_50 = compute_rolling_sortino_ratios(etf_prices, n=50)\n",
    "\n",
    "print(f\"computing the rolling sortino ratios for all assets for the long time frame ({time_frame_long} days)...\")\n",
    "rolling_sortino_ratios_etf_200 = compute_rolling_sortino_ratios(etf_prices, n=200)\n",
    "\n",
    "print(\" \")\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "#the spreads between the sortino ratios of all assets and the benchmark\n",
    "print(f\"computing the rolling sortino ratios for all assets minus the benchmark for the short time frame ({time_frame_short} days)...\")\n",
    "rolling_sortino_ratios_benchmark_minus_etf_21  = compute_rolling_sortino_ratios_benchmark_minus_asset(etf_prices,'SPY', n=21)\n",
    "\n",
    "print(f\"computing the rolling sortino ratios for all assets minus the benchmark for the mid time frame ({time_frame_mid} days)...\")\n",
    "rolling_sortino_ratios_benchmark_minus_etf_50  = compute_rolling_sortino_ratios_benchmark_minus_asset(etf_prices,'SPY', n=50)\n",
    "\n",
    "print(f\"computing the rolling sortino ratios for all assets minus the benchmark for the long time frame ({time_frame_long} days)...\")\n",
    "rolling_sortino_ratios_benchmark_minus_etf_200  = compute_rolling_sortino_ratios_benchmark_minus_asset(etf_prices,'SPY', n=200)\n",
    "\n",
    "print(\" \")\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "print(\"Computing pairwise spreads between assets within each category...\")\n",
    "print(f\"Computing pairwise spreads for the short time frame ({time_frame_short} days)...\")\n",
    "pairwise_spreads_21 = create_pairwise_spreads(etf_dataframes, window=time_frame_short)\n",
    "\n",
    "print(f\"Computing pairwise spreads for the mid time frame ({time_frame_mid} days)...\")\n",
    "pairwise_spreads_50 = create_pairwise_spreads(etf_dataframes, window=time_frame_mid)\n",
    "\n",
    "print(f\"Computing pairwise spreads for the long time frame ({time_frame_long} days)...\")\n",
    "pairwise_spreads_200 = create_pairwise_spreads(etf_dataframes, window=time_frame_long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#plot pairwise spreads\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Plot the pairwise spreads for each category\n",
    "# Create interactive plots for pairwise spreads by category\n",
    "\n",
    "def plot_pairwise_spreads(pairwise_spreads_dict, title=\"Pairwise Spreads by Category\", time_frame=None):\n",
    "    \"\"\"\n",
    "    Creates an interactive plot showing pairwise spreads for each category with dropdown selection.\n",
    "    Uses subplots to show both the spreads over time and their z-scores.\n",
    "    \n",
    "    Parameters:\n",
    "        pairwise_spreads_dict (dict): Dictionary where keys are categories and values are DataFrames with spread columns\n",
    "        title (str): Main title for the plot\n",
    "        time_frame (int): Number of days for the time frame (for display in title)\n",
    "    \"\"\"\n",
    "    # Get list of categories\n",
    "    categories = list(pairwise_spreads_dict.keys())\n",
    "    \n",
    "    # Create figure with subplots - one for spreads and one for z-scores\n",
    "    fig = make_subplots(rows=2, cols=1, \n",
    "                        shared_xaxes=True, \n",
    "                        vertical_spacing=0.1,\n",
    "                        subplot_titles=(\"Pairwise Spreads\", \"Z-Scores\"),\n",
    "                        row_heights=[0.7, 0.3])\n",
    "    \n",
    "    # Add traces for first category (will be visible)\n",
    "    if categories:\n",
    "        first_category = categories[0]\n",
    "        first_df = pairwise_spreads_dict[first_category]\n",
    "        \n",
    "        # For the first category, add line traces to top subplot\n",
    "        for spread in first_df.columns:\n",
    "            # Add spread line to top subplot\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=first_df.index,\n",
    "                    y=first_df[spread],\n",
    "                    mode=\"lines\",\n",
    "                    name=spread,\n",
    "                    line=dict(width=1.5),\n",
    "                    opacity=0.8,\n",
    "                    hovertemplate='%{y:.4f}<extra>%{fullData.name} (%{x})</extra>'\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            \n",
    "            # Calculate z-score for the spread and add as bar to bottom subplot\n",
    "            z_score = (first_df[spread].iloc[-1] - first_df[spread].mean()) / first_df[spread].std()\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=[spread],\n",
    "                    y=[z_score],\n",
    "                    name=f\"Z-Score: {spread}\",\n",
    "                    text=f\"{z_score:.2f}\",\n",
    "                    textposition='auto',\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "    \n",
    "    # Create dropdown menu items\n",
    "    buttons = []\n",
    "    \n",
    "    for category in categories:\n",
    "        # Create a list of booleans for visibility\n",
    "        # True for traces of this category, False for all others\n",
    "        visibility = []\n",
    "        \n",
    "        # Counter to track trace position across all categories\n",
    "        trace_counter = 0\n",
    "        \n",
    "        for cat in categories:\n",
    "            df = pairwise_spreads_dict[cat]\n",
    "            # For each spread in the current category\n",
    "            for _ in range(len(df.columns)):\n",
    "                # Set visibility based on whether it's the selected category\n",
    "                # Need to account for 2 traces per spread (line + bar)\n",
    "                visibility.append(cat == category)  # For line trace\n",
    "                visibility.append(cat == category)  # For bar trace\n",
    "                trace_counter += 2\n",
    "                \n",
    "        time_frame_str = f\" ({time_frame} Days)\" if time_frame else \"\"\n",
    "        buttons.append(\n",
    "            dict(\n",
    "                label=category,\n",
    "                method=\"update\",\n",
    "                args=[\n",
    "                    {\"visible\": visibility},\n",
    "                    {\"title\": f\"Pairwise Spreads for {category}{time_frame_str}\"}\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Add all other category traces (initially hidden)\n",
    "    for category in categories[1:]:\n",
    "        df = pairwise_spreads_dict[category]\n",
    "        for spread in df.columns:\n",
    "            # Add line trace (hidden)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=df.index,\n",
    "                    y=df[spread],\n",
    "                    mode=\"lines\",\n",
    "                    name=spread,\n",
    "                    line=dict(width=1.5),\n",
    "                    opacity=0.8,\n",
    "                    visible=False,\n",
    "                    hovertemplate='%{y:.4f}<extra>%{fullData.name} (%{x})</extra>'\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            \n",
    "            # Add z-score bar (hidden)\n",
    "            z_score = (df[spread].iloc[-1] - df[spread].mean()) / df[spread].std()\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=[spread],\n",
    "                    y=[z_score],\n",
    "                    name=f\"Z-Score: {spread}\",\n",
    "                    text=f\"{z_score:.2f}\",\n",
    "                    textposition='auto',\n",
    "                    visible=False,\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "    \n",
    "    # Display time frame in title if provided\n",
    "    time_frame_str = f\" ({time_frame} Days)\" if time_frame else \"\"\n",
    "    \n",
    "    # Update layout with dropdown menu\n",
    "    fig.update_layout(\n",
    "        title=f\"Pairwise Spreads for {categories[0]}{time_frame_str}\",\n",
    "        template=\"plotly_dark\",\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                active=0,\n",
    "                buttons=buttons,\n",
    "                direction=\"down\",\n",
    "                pad={\"r\": 10, \"t\": 10},\n",
    "                showactive=True,\n",
    "                x=0.05,  # Dropdown positioned on the left\n",
    "                xanchor=\"left\",\n",
    "                y=1.15,\n",
    "                yanchor=\"top\"\n",
    "            )\n",
    "        ],\n",
    "        height=800,  # Increased height to accommodate both plots\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"left\",\n",
    "            x=0.4  # Increased x position to move legend further right of dropdown\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Add a horizontal line at y=0 to show the zero level in top plot\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"white\", opacity=0.5, row=1, col=1)\n",
    "    \n",
    "    # Add horizontal lines at y=-2, 0, 2 to show standard deviation levels in bottom plot\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"white\", opacity=0.5, row=2, col=1)\n",
    "    fig.add_hline(y=2, line_dash=\"dot\", line_color=\"red\", opacity=0.5, row=2, col=1)\n",
    "    fig.add_hline(y=-2, line_dash=\"dot\", line_color=\"red\", opacity=0.5, row=2, col=1)\n",
    "    \n",
    "    # Update axes labels\n",
    "    fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Spread Value\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Z-Score\", row=2, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create separate figures for each time frame\n",
    "print(\"Plotting pairwise spreads for the short time frame...\")\n",
    "fig_short = plot_pairwise_spreads(pairwise_spreads_21, f\"Pairwise Return Spreads - Short Term\", time_frame_short)\n",
    "fig_short.show()\n",
    "\n",
    "print(f\"Plotting pairwise spreads for the mid time frame ({time_frame_mid} days)...\")\n",
    "fig_mid = plot_pairwise_spreads(pairwise_spreads_50, f\"Pairwise Return Spreads - Medium Term\", time_frame_mid)\n",
    "fig_mid.show()\n",
    "\n",
    "print(f\"Plotting pairwise spreads for the long time frame ({time_frame_long} days)...\")\n",
    "fig_long = plot_pairwise_spreads(pairwise_spreads_200, f\"Pairwise Return Spreads - Long Term\", time_frame_long)\n",
    "fig_long.show()\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot pairwise spreads\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Plot the pairwise spreads for each category and time frame\n",
    "# Create interactive plots for pairwise spreads by category and time frame\n",
    "\n",
    "def plot_pairwise_spreads(pairwise_spreads_dict_by_timeframe, title=\"Pairwise Spreads\", time_frames=None):\n",
    "    \"\"\"\n",
    "    Creates an interactive plot showing pairwise spreads for each category and time frame with dropdown selections.\n",
    "    Uses subplots to show both the spreads over time and their z-scores.\n",
    "    \n",
    "    Parameters:\n",
    "        pairwise_spreads_dict_by_timeframe (dict): Dictionary with time frames as keys and dictionaries of category spreads as values\n",
    "        title (str): Main title for the plot\n",
    "        time_frames (dict): Dictionary mapping time frame keys to display names (e.g. {'short': 21})\n",
    "    \"\"\"\n",
    "    # Get list of time frames and categories\n",
    "    time_frame_keys = list(pairwise_spreads_dict_by_timeframe.keys())\n",
    "    first_time_frame = time_frame_keys[0]\n",
    "    categories = list(pairwise_spreads_dict_by_timeframe[first_time_frame].keys())\n",
    "    first_category = categories[0]\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig = make_subplots(rows=2, cols=1, \n",
    "                        shared_xaxes=True, \n",
    "                        vertical_spacing=0.1,\n",
    "                        subplot_titles=(\"Pairwise Spreads\", \"Z-Scores\"),\n",
    "                        row_heights=[0.7, 0.3])\n",
    "    \n",
    "    # Dictionary to track traces by their ID\n",
    "    trace_indices = {}\n",
    "    trace_idx = 0\n",
    "    \n",
    "    # Add all traces for all time frames and categories (initially hide most)\n",
    "    for time_frame_key in time_frame_keys:\n",
    "        for category in categories:\n",
    "            df = pairwise_spreads_dict_by_timeframe[time_frame_key][category]\n",
    "            \n",
    "            # Store starting index for this combination\n",
    "            current_combo = f\"{time_frame_key}_{category}\"\n",
    "            trace_indices[current_combo] = []\n",
    "            \n",
    "            # For each spread in the category\n",
    "            for spread in df.columns:\n",
    "                # Add spread line\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=df.index,\n",
    "                        y=df[spread],\n",
    "                        mode=\"lines\",\n",
    "                        name=spread,\n",
    "                        line=dict(width=1.5),\n",
    "                        opacity=0.8,\n",
    "                        visible=(time_frame_key == first_time_frame and category == first_category),\n",
    "                        hovertemplate='%{y:.4f}<extra>%{fullData.name} (%{x})</extra>'\n",
    "                    ),\n",
    "                    row=1, col=1\n",
    "                )\n",
    "                trace_indices[current_combo].append(trace_idx)\n",
    "                trace_idx += 1\n",
    "                \n",
    "                # Calculate z-score and add bar\n",
    "                z_score = (df[spread].iloc[-1] - df[spread].mean()) / df[spread].std()\n",
    "                fig.add_trace(\n",
    "                    go.Bar(\n",
    "                        x=[spread],\n",
    "                        y=[z_score],\n",
    "                        name=f\"Z-Score: {spread}\",\n",
    "                        text=f\"{z_score:.2f}\",\n",
    "                        textposition='auto',\n",
    "                        visible=(time_frame_key == first_time_frame and category == first_category),\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=2, col=1\n",
    "                )\n",
    "                trace_indices[current_combo].append(trace_idx)\n",
    "                trace_idx += 1\n",
    "    \n",
    "    # Create timeframe buttons\n",
    "    timeframe_buttons = []\n",
    "    for time_frame_key in time_frame_keys:\n",
    "        tf_days = time_frames.get(time_frame_key) if time_frames else time_frame_key\n",
    "        timeframe_buttons.append(\n",
    "            dict(\n",
    "                label=f\"{tf_days} Days\" if isinstance(tf_days, int) else time_frame_key,\n",
    "                method=\"update\",\n",
    "                args=[\n",
    "                    {\"visible\": [False] * trace_idx},  # Hide all traces initially\n",
    "                    {\"title\": f\"Pairwise Spreads for {first_category} ({tf_days} Days)\"}\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        # Set visibility for the selected timeframe and first category\n",
    "        visible_traces = trace_indices[f\"{time_frame_key}_{first_category}\"]\n",
    "        for i in visible_traces:\n",
    "            timeframe_buttons[-1][\"args\"][0][\"visible\"][i] = True\n",
    "    \n",
    "    # Create category buttons for each time frame\n",
    "    category_buttons = []\n",
    "    for category in categories:\n",
    "        category_buttons.append(\n",
    "            dict(\n",
    "                label=category,\n",
    "                method=\"update\",\n",
    "                args=[\n",
    "                    {\"visible\": [False] * trace_idx},  # Hide all traces initially\n",
    "                    {\"title\": f\"Pairwise Spreads for {category} ({time_frames.get(first_time_frame)} Days)\"}\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        # Set visibility for the selected category and first time frame\n",
    "        visible_traces = trace_indices[f\"{first_time_frame}_{category}\"]\n",
    "        for i in visible_traces:\n",
    "            category_buttons[-1][\"args\"][0][\"visible\"][i] = True\n",
    "    \n",
    "    # Update layout with dropdown menus\n",
    "    fig.update_layout(\n",
    "        title=f\"Pairwise Spreads for {first_category} ({time_frames.get(first_time_frame)} Days)\",\n",
    "        template=\"plotly_dark\",\n",
    "        updatemenus=[\n",
    "            # Time frame dropdown\n",
    "            dict(\n",
    "                active=0,\n",
    "                buttons=timeframe_buttons,\n",
    "                direction=\"down\",\n",
    "                pad={\"r\": 10, \"t\": 10},\n",
    "                showactive=True,\n",
    "                x=0.05,\n",
    "                xanchor=\"left\",\n",
    "                y=1.15,\n",
    "                yanchor=\"top\",\n",
    "                bgcolor=\"rgba(50, 50, 50, 0.7)\",\n",
    "                font=dict(color=\"white\"),\n",
    "                name=\"Time Frame\"\n",
    "            ),\n",
    "            # Category dropdown\n",
    "            dict(\n",
    "                active=0,\n",
    "                buttons=category_buttons,\n",
    "                direction=\"down\",\n",
    "                pad={\"r\": 10, \"t\": 10},\n",
    "                showactive=True,\n",
    "                x=0.35,\n",
    "                xanchor=\"left\",\n",
    "                y=1.15,\n",
    "                yanchor=\"top\",\n",
    "                bgcolor=\"rgba(50, 50, 50, 0.7)\",\n",
    "                font=dict(color=\"white\"),\n",
    "                name=\"Category\"\n",
    "            )\n",
    "        ],\n",
    "        # Add annotations for the dropdowns\n",
    "        annotations=[\n",
    "            dict(\n",
    "                text=\"Time Frame:\",\n",
    "                x=0.01,\n",
    "                y=1.15,\n",
    "                xref=\"paper\",\n",
    "                yref=\"paper\",\n",
    "                showarrow=False,\n",
    "                font=dict(size=14)\n",
    "            ),\n",
    "            dict(\n",
    "                text=\"Category:\",\n",
    "                x=0.3,\n",
    "                y=1.15,\n",
    "                xref=\"paper\",\n",
    "                yref=\"paper\",\n",
    "                showarrow=False,\n",
    "                font=dict(size=14)\n",
    "            )\n",
    "        ],\n",
    "        height=800,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"left\",\n",
    "            x=0.6\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Add reference lines\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"white\", opacity=0.5, row=1, col=1)\n",
    "    fig.add_hline(y=0, line_dash=\"dash\", line_color=\"white\", opacity=0.5, row=2, col=1)\n",
    "    fig.add_hline(y=2, line_dash=\"dot\", line_color=\"red\", opacity=0.5, row=2, col=1)\n",
    "    fig.add_hline(y=-2, line_dash=\"dot\", line_color=\"red\", opacity=0.5, row=2, col=1)\n",
    "    \n",
    "    # Update axes labels\n",
    "    fig.update_xaxes(title_text=\"Date\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Spread Value\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Z-Score\", row=2, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Combine all pairwise spreads into a single dictionary by time frame\n",
    "pairwise_spreads_by_timeframe = {\n",
    "    'short': pairwise_spreads_21,\n",
    "    'mid': pairwise_spreads_50,\n",
    "    'long': pairwise_spreads_200\n",
    "}\n",
    "\n",
    "# Define time frames for display\n",
    "time_frames_mapping = {\n",
    "    'short': time_frame_short,  # 21\n",
    "    'mid': time_frame_mid,      # 50\n",
    "    'long': time_frame_long     # 200\n",
    "}\n",
    "\n",
    "# Create a single figure with time frame and category dropdowns\n",
    "print(\"Creating interactive pairwise spreads plot with time frame and category selection...\")\n",
    "fig_combined = plot_pairwise_spreads(pairwise_spreads_by_timeframe, \"Pairwise Return Spreads\", time_frames_mapping)\n",
    "fig_combined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Create monthly resampled ETF dataframes\n",
    "etf_dataframes_monthly = {key: value.resample('M').last() for key, value in etf_dataframes.items()}\n",
    "\n",
    "# Create correlation matrices for each ETF dataframe using monthly data\n",
    "etf_dataframes_correlation_matrices = {key: np.log(value).diff().dropna().corr() for key, value in etf_dataframes_monthly.items()}\n",
    "\n",
    "# Function to get paired correlations in ascending order\n",
    "def get_sorted_correlations(corr_matrix):\n",
    "    # Get the lower triangular part of the correlation matrix (excluding diagonal)\n",
    "    mask = np.tril(np.ones(corr_matrix.shape), k=-1).astype(bool)\n",
    "    corr_pairs = []\n",
    "    \n",
    "    # Extract all pairwise correlations\n",
    "    for i, row in enumerate(corr_matrix.index):\n",
    "        for j, col in enumerate(corr_matrix.columns):\n",
    "            if mask[i, j]:  # Only take lower triangle to avoid duplicates\n",
    "                corr_pairs.append((f\"{row}-{col}\", corr_matrix.iloc[i, j]))\n",
    "    \n",
    "    # Sort by correlation value\n",
    "    corr_pairs.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # Return pair names and correlation values\n",
    "    return zip(*corr_pairs)\n",
    "\n",
    "# Function to calculate cointegration p-values for specific pairs\n",
    "def get_cointegration_pvals(df, correlation_pairs):\n",
    "    pairs = []\n",
    "    p_values = []\n",
    "    \n",
    "    for pair_name in correlation_pairs:\n",
    "        # Split the ticker pair\n",
    "        ticker1, ticker2 = pair_name.split('-')\n",
    "        \n",
    "        # Skip pairs with insufficient data\n",
    "        series1 = df[ticker1].dropna()\n",
    "        series2 = df[ticker2].dropna()\n",
    "        \n",
    "        common_idx = series1.index.intersection(series2.index)\n",
    "        if len(common_idx) < 10:  # Reduced minimum data points needed for monthly data\n",
    "            p_values.append(1.0)  # Use 1.0 as default p-value when test can't be run\n",
    "            continue\n",
    "            \n",
    "        s1 = series1.loc[common_idx]\n",
    "        s2 = series2.loc[common_idx]\n",
    "        \n",
    "        try:\n",
    "            # Regression to get residuals\n",
    "            X = np.array(s2).reshape(-1, 1)\n",
    "            X = np.hstack((np.ones(X.shape[0]).reshape(-1, 1), X))\n",
    "            y = np.array(s1).reshape(-1, 1)\n",
    "            \n",
    "            beta = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "            residuals = y - X.dot(beta)\n",
    "            \n",
    "            # ADF test on residuals\n",
    "            adf_result = adfuller(residuals.flatten(), autolag='AIC')\n",
    "            p_value = adf_result[1]\n",
    "            \n",
    "            p_values.append(p_value)\n",
    "        except:\n",
    "            p_values.append(1.0)  # Use 1.0 as default p-value when test fails\n",
    "    \n",
    "    return correlation_pairs, p_values\n",
    "\n",
    "# Create subplots with 3 rows\n",
    "first_key = list(etf_dataframes_correlation_matrices.keys())[0]\n",
    "first_df = etf_dataframes_monthly[first_key]\n",
    "first_matrix = etf_dataframes_correlation_matrices[first_key]\n",
    "\n",
    "# Get sorted correlations\n",
    "pair_names, pair_corrs = get_sorted_correlations(first_matrix)\n",
    "pair_names = list(pair_names)  # Convert to list for reuse\n",
    "\n",
    "# Get cointegration p-values for the same pairs in same order\n",
    "coint_pair_names, coint_p_values = get_cointegration_pvals(first_df, pair_names)\n",
    "\n",
    "# Convert p-values to -log10(p) for better visualization\n",
    "log_p_values = [-np.log10(p) if p > 0 else 15 for p in coint_p_values] if coint_p_values else []\n",
    "\n",
    "# Create subplots: heatmap on left, correlation and cointegration bar charts on right\n",
    "fig = make_subplots(\n",
    "    rows=2,\n",
    "    cols=2,\n",
    "    column_widths=[0.5, 0.5],\n",
    "    row_heights=[0.5, 0.5],\n",
    "    specs=[[{\"rowspan\": 2}, {}], \n",
    "           [None, {}]],\n",
    "    vertical_spacing=0.1,\n",
    "    horizontal_spacing=0.05,\n",
    "    subplot_titles=('Monthly Correlation Matrix', 'Monthly Sorted Pairwise Correlations', 'Monthly Cointegration Test (-log10 p-value)')\n",
    ")\n",
    "\n",
    "# Add heatmap trace on left side (spanning both rows)\n",
    "heatmap = go.Heatmap(\n",
    "    z=first_matrix.values,\n",
    "    x=first_matrix.columns,\n",
    "    y=first_matrix.index,\n",
    "    colorscale='RdBu_r',\n",
    "    zmid=0,\n",
    "    colorbar=dict(title='Correlation', y=0.5, len=0.85)\n",
    ")\n",
    "fig.add_trace(heatmap, row=1, col=1)\n",
    "\n",
    "# Add correlation bar chart on top right - removing its colorbar since it uses the same scale as heatmap\n",
    "bar = go.Bar(\n",
    "    x=pair_names,\n",
    "    y=pair_corrs,\n",
    "    marker=dict(\n",
    "        color=pair_corrs,\n",
    "        colorscale='RdBu_r',\n",
    "        showscale=False  # Hide duplicate colorbar\n",
    "    )\n",
    ")\n",
    "fig.add_trace(bar, row=1, col=2)\n",
    "\n",
    "# Add cointegration bar chart on bottom right\n",
    "if coint_pair_names and log_p_values:\n",
    "    coint_bar = go.Bar(\n",
    "        x=coint_pair_names,\n",
    "        y=log_p_values,\n",
    "        marker=dict(\n",
    "            color=log_p_values,\n",
    "            colorscale='Viridis',\n",
    "            colorbar=dict(title='-log10(p)', x=1.15, y=0.25, len=0.4)\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(coint_bar, row=2, col=2)\n",
    "\n",
    "# Add a horizontal line at .05 for cointegration\n",
    "fig.add_hline(y=-np.log10(0.05), line_dash='dash', line_color='red', row=2, col=2)\n",
    "\n",
    "# Create dropdown menu buttons\n",
    "buttons = []\n",
    "for key in etf_dataframes_correlation_matrices.keys():\n",
    "    matrix = etf_dataframes_correlation_matrices[key]\n",
    "    df = etf_dataframes_monthly[key]\n",
    "    pair_names, pair_corrs = get_sorted_correlations(matrix)\n",
    "    pair_names_list = list(pair_names)  # Convert to list for reuse\n",
    "    coint_pair_names, coint_p_values = get_cointegration_pvals(df, pair_names_list)\n",
    "    \n",
    "    log_p_values = [-np.log10(p) if p > 0 else 15 for p in coint_p_values] if coint_p_values else []\n",
    "    \n",
    "    buttons.append(\n",
    "        dict(\n",
    "            method='update',\n",
    "            label=key,\n",
    "            args=[{\n",
    "                'z': [matrix.values, None, None],\n",
    "                'x': [matrix.columns, pair_names_list, coint_pair_names],\n",
    "                'y': [matrix.index, pair_corrs, log_p_values],\n",
    "                'marker.color': [None, pair_corrs, log_p_values]\n",
    "            }]\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='ETF Analysis: Monthly Correlation and Cointegration',\n",
    "    updatemenus=[{\n",
    "        'buttons': buttons,\n",
    "        'direction': 'down',\n",
    "        'showactive': True,\n",
    "        'x': 0.1,\n",
    "        'y': 1.15,\n",
    "        'xanchor': 'left',\n",
    "        'yanchor': 'top'\n",
    "    }],\n",
    "    height=900,\n",
    ")\n",
    "\n",
    "# Format x-axes\n",
    "fig.update_xaxes(tickangle=90, tickfont=dict(size=8), row=1, col=2)\n",
    "fig.update_xaxes(tickangle=90, tickfont=dict(size=8), row=2, col=2)\n",
    "\n",
    "# Add axis titles\n",
    "fig.update_yaxes(title='Correlation', row=1, col=2)\n",
    "fig.update_yaxes(title='-log10(p-value)', row=2, col=2)\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prices_and_returns(df_dict, n=200):\n",
    "    \"\"\"\n",
    "    Plots, for each group of assets in a dictionary of DataFrames:\n",
    "      - The prices in the first subplot,\n",
    "      - The n-window returns in the second subplot,\n",
    "      - The n-window Sharpe ratio in the third subplot.\n",
    "\n",
    "    Provides a single dropdown to toggle which group to display.\n",
    "\n",
    "    Args:\n",
    "        df_dict (dict): A dictionary where each key is a group name and each value is a\n",
    "                        pandas DataFrame with a DateTime index (prices) and columns as asset tickers.\n",
    "        n (int): The window length for computing returns (periods=n in pct_change).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    # Create a 3-row figure:\n",
    "    # 1) first row for prices,\n",
    "    # 2) second row for n-window returns,\n",
    "    # 3) third row for n-window Sharpe ratio.\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.06,\n",
    "        subplot_titles=[\n",
    "            \"Prices\",\n",
    "            f\"{n}-Window Returns\",\n",
    "            f\"{n}-Window Sharpe Ratio\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    group_names = list(df_dict.keys())\n",
    "    total_traces = 0\n",
    "    group_traces_visibility = []  # Will store (start_idx, end_idx) for each group\n",
    "\n",
    "    # For each group, add 3 traces per asset:\n",
    "    #   1) Price trace\n",
    "    #   2) Returns trace\n",
    "    #   3) Sharpe ratio trace\n",
    "    for i, (group_name, df) in enumerate(df_dict.items()):\n",
    "        # Calculate n-window returns\n",
    "        df_returns = df.pct_change(periods=n)\n",
    "\n",
    "        # Calculate approximate n-window Sharpe (no RF, daily frequency assumed)\n",
    "        #  rolling_mean: average returns over the window\n",
    "        #  volatility: std of all returns over the window\n",
    "        #  ratio = sqrt(n) * rolling_mean / volatility\n",
    "        rolling_mean = df_returns.rolling(window=n).mean()\n",
    "        volatility = df_returns.rolling(window=n).std()\n",
    "        sharpe_ratio = (rolling_mean * np.sqrt(n)) / volatility\n",
    "\n",
    "        start_idx = total_traces\n",
    "        for col in df.columns:\n",
    "            # 1) Price trace (row=1)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=df.index,\n",
    "                    y=df[col],\n",
    "                    mode='lines',\n",
    "                    name=f\"{col} ({group_name}) - Price\",\n",
    "                    visible=(True if i == 0 else False)\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            total_traces += 1\n",
    "\n",
    "            # 2) Returns trace (row=2)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=df_returns.index,\n",
    "                    y=df_returns[col],\n",
    "                    mode='lines',\n",
    "                    name=f\"{col} ({group_name}) - {n}-Win Return\",\n",
    "                    visible=(True if i == 0 else False)\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "            total_traces += 1\n",
    "\n",
    "            # 3) Sharpe ratio trace (row=3)\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=sharpe_ratio.index,\n",
    "                    y=sharpe_ratio[col],\n",
    "                    mode='lines',\n",
    "                    name=f\"{col} ({group_name}) - Sharpe\",\n",
    "                    visible=(True if i == 0 else False)\n",
    "                ),\n",
    "                row=3, col=1\n",
    "            )\n",
    "            total_traces += 1\n",
    "\n",
    "        end_idx = total_traces - 1\n",
    "        group_traces_visibility.append((start_idx, end_idx))\n",
    "\n",
    "    # Build dropdown buttons to toggle each group's traces\n",
    "    buttons = []\n",
    "    for i, group_name in enumerate(group_names):\n",
    "        visible_config = [False] * total_traces\n",
    "\n",
    "        start_idx, end_idx = group_traces_visibility[i]\n",
    "        # Make only this group's traces visible\n",
    "        for j in range(start_idx, end_idx + 1):\n",
    "            visible_config[j] = True\n",
    "\n",
    "        buttons.append({\n",
    "            \"label\": group_name,\n",
    "            \"method\": \"update\",\n",
    "            \"args\": [{\"visible\": visible_config}],\n",
    "        })\n",
    "\n",
    "    # Add the dropdown menu & layout options\n",
    "    fig.update_layout(\n",
    "        updatemenus=[\n",
    "            {\n",
    "                \"buttons\": buttons,\n",
    "                \"direction\": \"down\",\n",
    "                \"showactive\": True,\n",
    "            }\n",
    "        ],\n",
    "        title=\"Prices, Returns & Sharpe by Asset Group\",\n",
    "        template=\"plotly_dark\",\n",
    "        height=2400\n",
    "    )\n",
    "\n",
    "    # Label axes\n",
    "    fig.update_xaxes(title_text=\"Date\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Returns\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Sharpe\", row=3, col=1)\n",
    "\n",
    "    # Add a horizontal line at y=0 for returns subplot (row=2)\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        xref=\"paper\", x0=0, x1=1,\n",
    "        yref=\"y2\", y0=0, y1=0,\n",
    "        line=dict(color=\"white\", dash=\"dash\")\n",
    "    )    # Add a horizontal line at y=0 for returns subplot (row=1)\n",
    "    \n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        xref=\"paper\", x0=0, x1=1,\n",
    "        yref=\"y3\", y0=0, y1=0,\n",
    "        line=dict(color=\"white\", dash=\"dash\")\n",
    "    )\n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "\n",
    "plot_prices_and_returns(etf_dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff_from_average(df_dict, n=200):\n",
    "    \"\"\"\n",
    "    Plots, for each group of assets in a dictionary of DataFrames:\n",
    "      - The difference between each asset's n-window returns and the average returns in the first subplot,\n",
    "      - The difference between each asset's n-window Sharpe ratio and the average Sharpe ratio in the second subplot.\n",
    "    (Horizontal lines removed as requested.)\n",
    "\n",
    "    Args:\n",
    "        df_dict (dict): Dictionary of group names and DataFrames (with DateTime index and asset columns)\n",
    "        n (int): Window length for computing returns (pct_change(periods=n)) and metrics.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.06,\n",
    "        subplot_titles=[\n",
    "            f\"{n}-Window Returns Difference (Asset - Average)\",\n",
    "            f\"{n}-Window Sharpe Ratio Difference (Asset - Average)\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    group_names = list(df_dict.keys())\n",
    "    total_traces = 0\n",
    "    group_traces_visibility = []\n",
    "\n",
    "    all_returns_diff = []\n",
    "    all_sharpe_diff = []\n",
    "\n",
    "    for i, (group_name, df) in enumerate(df_dict.items()):\n",
    "        df_returns = df.pct_change(periods=n)\n",
    "        rolling_mean = df_returns.rolling(window=n).mean()\n",
    "        volatility = df_returns.rolling(window=n).std()\n",
    "        sharpe_ratio = (rolling_mean * np.sqrt(n)) / (volatility)\n",
    "\n",
    "        avg_returns = df_returns.mean(axis=1)\n",
    "        avg_sharpe = sharpe_ratio.mean(axis=1)\n",
    "\n",
    "        start_idx = total_traces\n",
    "        for col in df.columns:\n",
    "            diff_returns = df_returns[col] - avg_returns\n",
    "            diff_sharpe = sharpe_ratio[col] - avg_sharpe\n",
    "\n",
    "            all_returns_diff.append(diff_returns)\n",
    "            all_sharpe_diff.append(diff_sharpe)\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=df.index,\n",
    "                    y=diff_returns,\n",
    "                    mode='lines',\n",
    "                    name=f\"{col} ({group_name}) - {n}-Win Return Diff\",\n",
    "                    visible=(True if i == 0 else False)\n",
    "                ),\n",
    "                row=1, col=1\n",
    "            )\n",
    "            total_traces += 1\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=df.index,\n",
    "                    y=diff_sharpe,\n",
    "                    mode='lines',\n",
    "                    name=f\"{col} ({group_name}) - Sharpe Diff\",\n",
    "                    visible=(True if i == 0 else False)\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "            total_traces += 1\n",
    "\n",
    "        group_traces_visibility.append((start_idx, total_traces - 1))\n",
    "\n",
    "    buttons = []\n",
    "    for i, group_name in enumerate(group_names):\n",
    "        visible_config = [False] * total_traces\n",
    "        start_idx, end_idx = group_traces_visibility[i]\n",
    "        for j in range(start_idx, end_idx + 1):\n",
    "            visible_config[j] = True\n",
    "        buttons.append({\n",
    "            \"label\": group_name,\n",
    "            \"method\": \"update\",\n",
    "            \"args\": [{\"visible\": visible_config}],\n",
    "        })\n",
    "\n",
    "    all_returns_diff = pd.concat(all_returns_diff).dropna()\n",
    "    all_sharpe_diff = pd.concat(all_sharpe_diff).dropna()\n",
    "    #add horizontal line at y=0\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        xref=\"paper\", x0=0, x1=1,\n",
    "        yref=\"y1\", y0=0, y1=0,\n",
    "        line=dict(color=\"white\", dash=\"dash\")\n",
    "    )\n",
    "    \n",
    "    fig.add_shape(    \n",
    "        type=\"line\",\n",
    "        xref=\"paper\", x0=0, x1=1,\n",
    "        yref=\"y2\", y0=0, y1=0,\n",
    "        line=dict(color=\"white\", dash=\"dash\")\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        updatemenus=[{\n",
    "            \"buttons\": buttons,\n",
    "            \"direction\": \"down\",\n",
    "            \"showactive\": True,\n",
    "        }],\n",
    "        title=\"Differences from Average by Asset Group\",\n",
    "        template=\"plotly_dark\",\n",
    "        height=1600\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Returns Diff\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Sharpe Diff\", row=2, col=1)\n",
    "\n",
    "    fig.show()\n",
    "plot_diff_from_average(etf_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#plot absolute and relative sortino ratios on a table\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_combined_table(df, title='Combined Sortino Indicators'):\n",
    "    \"\"\"\n",
    "    Plots a combined table with indicators for Sortino differences and integer-based standard deviation categories,\n",
    "    highlighting the direction of deviations (positive or negative).\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Combined DataFrame with 'Ticker', Sortino differences, and integer SD categories.\n",
    "        title (str): Title of the table.\n",
    "    \"\"\"\n",
    "    # Define color mappings for integer-based deviation categories\n",
    "    deviation_colors = {\n",
    "        3: 'lightgreen',   # z > 3\n",
    "        2: 'yellow',       # 2 < z <= 3\n",
    "        1: 'orange',       # 1 < z <= 2\n",
    "        0: 'white',        # -1 < z <= 1\n",
    "        -1: 'lightblue',   # -2 < z <= -1\n",
    "        -2: 'coral',       # -3 < z <= -2\n",
    "        -3: 'lightcoral'   # z <= -3\n",
    "    }\n",
    "    \n",
    "    # Initialize fill colors based on deviation categories and Sortino differences\n",
    "    fill_colors = []\n",
    "    for _, row in df.iterrows():\n",
    "        row_colors = []\n",
    "        for col in df.columns:\n",
    "            # Color for Ticker column\n",
    "            if col == 'Ticker':\n",
    "                row_colors.append('lightgrey')\n",
    "            \n",
    "            # Color for \"Relative performance\" boolean columns\n",
    "            elif 'Relative performance' in col:\n",
    "                if row[col]:\n",
    "                    row_colors.append('lightgreen')  # Underperforming\n",
    "                else:\n",
    "                    row_colors.append('white')       # Overperforming\n",
    "            \n",
    "            # Color for integer-based SD deviation columns\n",
    "            else:\n",
    "                # Fetch the integer deviation value\n",
    "                deviation = row[col]\n",
    "                # Get the color from the dictionary, default to white if not found\n",
    "                color = deviation_colors.get(deviation, 'white')\n",
    "                row_colors.append(color)\n",
    "        fill_colors.append(row_colors)\n",
    "    \n",
    "    # Transpose fill_colors to match Plotly's column-wise format\n",
    "    fill_colors_transposed = list(map(list, zip(*fill_colors)))\n",
    "    \n",
    "    # Replace boolean values with descriptive text for Sortino differences\n",
    "    display_df = df.copy()\n",
    "    for col in display_df.columns:\n",
    "        if 'Relative performance' in col:\n",
    "            display_df[col] = display_df[col].apply(lambda x: 'Underperforming' if x else 'Overperforming')\n",
    "    \n",
    "    # Create the Plotly table\n",
    "    fig = go.Figure(data=[go.Table(\n",
    "        header=dict(\n",
    "            values=['<b>' + col.replace('_', ' ') + '</b>' for col in display_df.columns],\n",
    "            fill_color='paleturquoise',\n",
    "            align='center',\n",
    "            font=dict(color='black', size=12)\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[display_df[col] for col in display_df.columns],\n",
    "            fill_color=fill_colors_transposed,\n",
    "            align='center',\n",
    "            font=dict(color='black', size=11)\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    # Update layout for aesthetics\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        template='plotly_white',\n",
    "        height=800,\n",
    "        margin=dict(l=50, r=50, t=80, b=200)  # Increased bottom margin for legend\n",
    "    )\n",
    "    \n",
    "    # Add an updated legend using annotations\n",
    "    legend_text = (\n",
    "        \"<b>Legend (Integer SD Buckets):</b><br>\"\n",
    "        \"3 => z > 3<br>\"\n",
    "        \"2 => 2 < z <= 3<br>\"\n",
    "        \"1 => 1 < z <= 2<br>\"\n",
    "        \"0 => -1 < z <= 1<br>\"\n",
    "        \"-1 => -2 < z <= -1<br>\"\n",
    "        \"-2 => -3 < z <= -2<br>\"\n",
    "        \"-3 => z <= -3<br><br>\"\n",
    "        \"<b>Performance Indicators:</b><br>\"\n",
    "        \"Light Green: Underperforming<br>\"\n",
    "        \"White: Overperforming\"\n",
    "    )\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        text=legend_text,\n",
    "        showarrow=False,\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.5, y=-0.3,\n",
    "        xanchor='center',\n",
    "        yanchor='top',\n",
    "        font=dict(color='black', size=12)\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "#Compute absolute and relative sortino ratios on a table for etfs\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "\n",
    "latest_sortino_differences_indicators = create_sortino_negative_indicators(\n",
    "    rolling_sortino_ratios_etf_50,\n",
    "    rolling_sortino_ratios_etf_200\n",
    ")\n",
    "\n",
    "\n",
    "sortino_std_deviation_table = create_sortino_std_deviation_table(\n",
    "    rolling_sortino_ratios_etf_50,\n",
    "    rolling_sortino_ratios_etf_200\n",
    ")\n",
    "\n",
    "\n",
    "price_std_deviation_table = create_price_std_deviation_table(etf_prices, window_sizes=[50, 200])\n",
    "\n",
    "\n",
    "combined_df = latest_sortino_differences_indicators.merge(\n",
    "    sortino_std_deviation_table,\n",
    "    on='Ticker',\n",
    "    how='left'\n",
    ").merge(\n",
    "    price_std_deviation_table,\n",
    "    on='Ticker',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "combined_df = combined_df.sort_values(\n",
    "    by=['Std Dev Direction for 200_Day Sortino Ratio']\n",
    ").reset_index(drop=True)\n",
    "\n",
    "plot_combined_table(\n",
    "    combined_df,\n",
    "    title='Combined Sortino Indicators'\n",
    ")\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "z_score_50 = pd.DataFrame()\n",
    "z_score_200 = pd.DataFrame()\n",
    "\n",
    "z_score_sortino_ratio_50       = calculate_z_scores(rolling_sortino_ratios_etf_50)\n",
    "z_score_benchmark_minus_etf_50 = calculate_z_scores(rolling_sortino_ratios_benchmark_minus_etf_50)\n",
    "\n",
    "z_score_50['50 day Sortino Ratio (z score)'] = z_score_sortino_ratio_50\n",
    "z_score_50['50 day Benchmark Minus ETF Sortino Ratio (z score)'] = z_score_benchmark_minus_etf_50\n",
    "z_score_50.sort_values(by='50 day Sortino Ratio (z score)', ascending=True, inplace=True)\n",
    "\n",
    "\n",
    "z_score_200['200 day Sortino Ratio (z score)'] = calculate_z_scores(rolling_sortino_ratios_etf_200)\n",
    "z_score_200['200 day Benchmark Minus ETF Sortino Ratio (z score)'] = calculate_z_scores(rolling_sortino_ratios_benchmark_minus_etf_200)\n",
    "z_score_200.sort_values(by='200 day Sortino Ratio (z score)', ascending=True, inplace=True)\n",
    "\n",
    "#plot 50 day z scores, truncate decimals to 2\n",
    "z_score_50 = z_score_50.round(2)\n",
    "z_score_200 = z_score_200.round(2)\n",
    "\n",
    "\n",
    "# Create figure for 50-day z-scores with color coding using 0.5 threshold\n",
    "fig1 = go.Figure(data=[go.Table(\n",
    "    header=dict(\n",
    "        values=['Ticker', '50 day Sortino Ratio (z score)', '50 day Benchmark Minus ETF Sortino Ratio (z score)'],\n",
    "        fill_color='paleturquoise',\n",
    "        align='center',\n",
    "        font=dict(size=12)\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=[z_score_50.index, z_score_50['50 day Sortino Ratio (z score)'], \n",
    "                z_score_50['50 day Benchmark Minus ETF Sortino Ratio (z score)']],\n",
    "        fill_color=[\n",
    "            'lightgrey',\n",
    "            z_score_50['50 day Sortino Ratio (z score)'].apply(\n",
    "                lambda x: 'lightgreen' if x > 0.5 else ('lightcoral' if x < -0.5 else 'white')),\n",
    "            z_score_50['50 day Benchmark Minus ETF Sortino Ratio (z score)'].apply(\n",
    "                lambda x: 'lightgreen' if x > 0.5 else ('lightcoral' if x < -0.5 else 'white'))\n",
    "        ],\n",
    "        align='center')\n",
    ")])\n",
    "\n",
    "fig1.update_layout(\n",
    "    title='50 Day Z-Scores for Sortino Ratios',\n",
    "    height=600, \n",
    "    margin=dict(l=10, r=10, t=50, b=10)\n",
    ")\n",
    "fig1.show()\n",
    "\n",
    "# Create figure for 200-day z-scores with color coding using 0.5 threshold\n",
    "fig2 = go.Figure(data=[go.Table(\n",
    "    header=dict(\n",
    "        values=['Ticker', '200 day Sortino Ratio (z score)', '200 day Benchmark Minus ETF Sortino Ratio (z score)'],\n",
    "        fill_color='paleturquoise',\n",
    "        align='center',\n",
    "        font=dict(size=12)\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=[z_score_200.index, z_score_200['200 day Sortino Ratio (z score)'], \n",
    "                z_score_200['200 day Benchmark Minus ETF Sortino Ratio (z score)']],\n",
    "        fill_color=[\n",
    "            'lightgrey',\n",
    "            z_score_200['200 day Sortino Ratio (z score)'].apply(\n",
    "                lambda x: 'lightgreen' if x > 0.5 else ('lightcoral' if x < -0.5 else 'white')),\n",
    "            z_score_200['200 day Benchmark Minus ETF Sortino Ratio (z score)'].apply(\n",
    "                lambda x: 'lightgreen' if x > 0.5 else ('lightcoral' if x < -0.5 else 'white'))\n",
    "        ],\n",
    "        align='center')\n",
    ")])\n",
    "\n",
    "fig2.update_layout(\n",
    "    title='200 Day Z-Scores for Sortino Ratios',\n",
    "    height=600,\n",
    "    margin=dict(l=10, r=10, t=50, b=10)\n",
    ")\n",
    "fig2.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_50 = pd.DataFrame()\n",
    "z_score_200 = pd.DataFrame()\n",
    "\n",
    "z_score_sortino_ratio_50       = calculate_z_scores(rolling_sortino_ratios_etf_50)\n",
    "z_score_benchmark_minus_etf_50 = calculate_z_scores(rolling_sortino_ratios_benchmark_minus_etf_50)\n",
    "\n",
    "z_score_50['50 day Sortino Ratio (z score)'] = z_score_sortino_ratio_50\n",
    "z_score_50['50 day Benchmark Minus ETF Sortino Ratio (z score)'] = z_score_benchmark_minus_etf_50\n",
    "z_score_50.sort_values(by='50 day Sortino Ratio (z score)', ascending=True, inplace=True)\n",
    "\n",
    "\n",
    "z_score_200['200 day Sortino Ratio (z score)'] = calculate_z_scores(rolling_sortino_ratios_etf_200)\n",
    "z_score_200['200 day Benchmark Minus ETF Sortino Ratio (z score)'] = calculate_z_scores(rolling_sortino_ratios_benchmark_minus_etf_200)\n",
    "z_score_200.sort_values(by='200 day Sortino Ratio (z score)', ascending=True, inplace=True)\n",
    "\n",
    "#plot 50 day z scores, truncate decimals to 2\n",
    "z_score_50 = z_score_50.round(2)\n",
    "z_score_200 = z_score_200.round(2)\n",
    "\n",
    "#combine both dataframes\n",
    "z_score_combined = pd.concat([z_score_50, z_score_200], axis=1)\n",
    "\n",
    "\n",
    "#sort columns by 200 day z score first, then 50 day z score\n",
    "z_score_combined = z_score_combined.reindex(sorted(z_score_combined.columns, key=lambda x: (x.split()[0], x.split()[2])), axis=1)\n",
    "# Create figure for combined z-scores with color coding using 0.5 threshold\n",
    "\n",
    "\n",
    "#create a fig for z_score_combined\n",
    "#make sure there is an option to sort by which column i select via a drop down\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "def plot_z_score_combined(z_score_combined):\n",
    "    # Define the columns for the dropdown options\n",
    "    columns = z_score_combined.columns.tolist()\n",
    "    \n",
    "    # Create the initial figure with the data sorted by the first column\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add the initial table trace (sorted by first column)\n",
    "    sorted_df = z_score_combined.sort_values(by=columns[0], ascending=True)\n",
    "    \n",
    "    # Define a function to determine cell color based on z-score value and column type\n",
    "    def get_cell_color(value, column_name):\n",
    "        if pd.isna(value):\n",
    "            return 'white'\n",
    "        \n",
    "        # Check if this is a \"Benchmark Minus ETF\" column (inverse coloring logic)\n",
    "        if \"Benchmark Minus ETF\" in column_name:\n",
    "            # For benchmark minus ETF columns: green for above 1, red for below -0.5\n",
    "            if value > 1:\n",
    "                return 'lightgreen'\n",
    "            elif value < -0.5:\n",
    "                return 'lightcoral'\n",
    "            else:\n",
    "                return 'white'\n",
    "        else:\n",
    "            # For regular sortino columns: red for above 1, green for below -0.5\n",
    "            if value > 1:\n",
    "                return 'lightcoral'\n",
    "            elif value < -0.5:\n",
    "                return 'lightgreen'\n",
    "            else:\n",
    "                return 'white'\n",
    "    \n",
    "    table = go.Table(\n",
    "        header=dict(\n",
    "            values=['Ticker'] + columns,\n",
    "            fill_color='paleturquoise',\n",
    "            align='center',\n",
    "            font=dict(size=12)\n",
    "        ),\n",
    "        cells=dict(\n",
    "            values=[sorted_df.index] + [sorted_df[col] for col in columns],\n",
    "            fill_color=[\n",
    "                'lightgrey',  # Ticker column color\n",
    "                # For each data column, color cells based on value and column name\n",
    "                *[[get_cell_color(val, col) for val in sorted_df[col]] for col in columns]\n",
    "            ],\n",
    "            align='center',\n",
    "            format=[None] + ['.2f'] * len(columns)  # Format numbers to 2 decimal places\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(table)\n",
    "    \n",
    "    # Create dropdown menu options for sorting\n",
    "    buttons = []\n",
    "    \n",
    "    # Add buttons for each column (ascending only)\n",
    "    for i, col in enumerate(columns):\n",
    "        buttons.append(dict(\n",
    "            args=[{\n",
    "                'cells': {\n",
    "                    'values': [z_score_combined.sort_values(by=col, ascending=True).index] + \n",
    "                              [z_score_combined.sort_values(by=col, ascending=True)[c] for c in columns],\n",
    "                    'fill': {\n",
    "                        'color': [\n",
    "                            'lightgrey',  # Ticker column color\n",
    "                            # For each data column, color cells based on value and column name\n",
    "                            *[[get_cell_color(val, c) for val in z_score_combined.sort_values(by=col, ascending=True)[c]] for c in columns]\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }],\n",
    "            label=f\"{col} (Ascending)\",\n",
    "            method=\"update\"\n",
    "        ))\n",
    "    \n",
    "    # Update layout with dropdown menu\n",
    "    fig.update_layout(\n",
    "        title='Combined Z-Scores for Sortino Ratios',\n",
    "        updatemenus=[{\n",
    "            'buttons': buttons,\n",
    "            'direction': 'down',\n",
    "            'showactive': True,\n",
    "            'x': 0.1,\n",
    "            'y': 1.15,\n",
    "            'xanchor': 'left',\n",
    "            'yanchor': 'top'\n",
    "        }],\n",
    "        template='plotly_white',\n",
    "        height=600,\n",
    "        margin=dict(l=10, r=10, t=100, b=10)  # Increased top margin for dropdown\n",
    "    )\n",
    "    \n",
    "    # Add a color legend annotation with updated descriptions\n",
    "    legend_text = (\n",
    "        \"Color coding for Asset Sortino Ratio:<br>\" +\n",
    "        \"<span style='color:lightcoral'></span> z > 1: Significantly above average (potential overvaluation)<br>\" +\n",
    "        \"<span style='color:lightgreen'></span> z < -0.5: Significantly below average (potential undervaluation)<br>\" +\n",
    "        \"<br>Color coding for Benchmark Minus ETF:<br>\" +\n",
    "        \"<span style='color:lightgreen'></span> z > 1: ETF underperforming benchmark (potential buying opportunity)<br>\" +\n",
    "        \"<span style='color:lightcoral'></span> z < -0.5: ETF outperforming benchmark (potentially overvalued)<br>\" \n",
    "    )\n",
    "    \n",
    "    fig.add_annotation(\n",
    "        text=legend_text,\n",
    "        showarrow=False,\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=1.0, y=1.2,\n",
    "        xanchor='right',\n",
    "        yanchor='top',\n",
    "        font=dict(size=10),\n",
    "        bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "        bordercolor=\"black\",\n",
    "        borderwidth=1\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "plot_z_score_combined(z_score_combined)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
